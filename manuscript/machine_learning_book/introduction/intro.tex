\ifx\mlbook\undefined
    \documentclass[10pt,a4paper]{ctexbook}
    \providecommand{\pathroot}{../..}

    \usepackage[CJKbookmarks,colorlinks,linkcolor=red]{hyperref}
    \usepackage{geometry}
    \usepackage{amsmath}

    \geometry{left=3.0cm,right=3.0cm,top=2.5cm,bottom=2.5cm}
    \setmainfont{SimSun}
    \XeTeXlinebreaklocale "zh"
    \XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

    \begin{document}
    \setlength{\baselineskip}{20pt}
    \title{Logistic回归}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{Sep 8, 2017}
    \maketitle
    \tableofcontents
\fi

\chapter{绪论}
\section{发展历史}
\section{应用现状}
\section{概念介绍}

\begin{itemize}
\item 监督学习：利用一组已知类别的样本调整分类器的参数，\\使其达到所要求性能的过程
\item 一些符号定义：

$x^{(i)}$：指数据集中的第$i$个样本的特征类数据。

$y^{(i)}$：指数据集中的第$i$个样本的目标值。

$\left(x^{(i)},y^{(i)}\right)$：表示一个样本实例。

$\left\{\left(x^{(i)},y^{(i)}\right), i=1,...,N\right\}$：表示一个数据集。
\\例如，对于手写体识别来说，图片的像素表示即为特征$x$，图片表示的数字即为目标值$y$。

\end{itemize}

\begin{itemize}
\item 一个完整的有监督学习的开发流程：
\\(1) 获取数据，对数据做一些清洗、转换等操作。
\\(2) 将数据样本拆分成训练集、验证集和测试集。训练集用来训练模型，验证集用来评估模型效果和调参，测试集则用来评估最终的模型效果。
\\(3) 开发模型或直接使用开发好的模型工具，在训练集上进行训练。
\\(4) 获取训练好的模型，使用验证集评估其效果。如果没有达到预期，需要进一步对模型调参、获取新的特征等操作，直到满足训练效果为止。
\\(5) 使用训练好的模型，在测试集上评估其最终效果。
\end{itemize}

\textbf{交叉验证{\color{red} TODO}}

交叉验证（Cross Validation），有的时候也称作循环估计（Rotation Estimation），是一种统计学上将数据样本切割成较小子集的实用方法，该理论是由Seymour Geisser提出的。

在模式识别（Pattern Recognition）和机器学习（Machine Learning）的相关研究中，经常会将整个数据集合分成两个部分，分别是训练集合和测试集合。假设X是集合全体，A是全集X的非空真子集，那么非空集合X\textbackslash{A}则是集合A在全集X中的补集。于是可以先在A上面做训练和分析，而集合X\textbackslash{A}则用来做测试和验证。一开始的集合A被称作训练集，而它的补集X\textbackslash{A}被称作验证集或者测试集。这里有一个重要的观点就是：只有训练集才可以使用在模型的训练之中，而测试集必须在模型训练完成之后才被用来评估模型的误差。

\textbf{HoldOut检验（Hold-Out Method）}
这个方法是将原始的数据集合X随机分成两个集合A和X\textbackslash{A}，其中A作为训练集，X\textbackslash{A}作为测试集。先使用训练集训练模型，然后利用测试集验证模型的效果，记录最后的分类准确率作为Hold-Out下该模型的性能指标。比方说，处理时间序列模型是否准确的时候，把整个数据集合分成前后两部分，前部分占比70\%，后部分占比30\%。前部分来进行时间序列模型的训练，后部分用来测试改时间序列的准确性。其准确性可以用MAE，MAPE之类的统计指标来衡量。综上所述，该方法的好处就是处理起来简单，只需要把原始数据分成两个部分即可。但是从严格意义上来说，Hold-Out检验并不算是交叉检验（Cross Validation），因为该方法没有达到交叉检验的思想，而且最后验证准确性的高低和原始数组的分类有很大的关系，所以该方法得到的结果在某些场景中并不具备特别大的说服力。在Hold-Out检验不够有说服力的情形下，有人提出了交叉验证这一个重要思想。

\textbf{交叉检验的常见形式}
假设有一个未知模型有一个或者多个未知的参数，并且有一个训练集。操作的过程就是对该模型的参数进行调整，使得该模型能够最大的反映训练集的特征。如果模型因为训练集过小或者参数不合适而产生过度拟合的情况，测试集的测试效果就可以得到验证。交叉验证是一种能够预测模型拟合性能的有效方法。

\textbf{彻底的交叉验证（Exhaustive Cross Validation）}
彻底的交叉验证方法指的是遍历全集X的所有非空真子集A。换句话说也就是把A当作训练集，X\textbackslash{A}是测试集。如果X中有n个元素，那么非空真子集A的选择方法则是$2^{n}-2$，这个方法的时间复杂度是指数级别的。

\begin{itemize}
\item 留P验证（Leave-p-out Cross Validation)
留p验证（LpO CV）指的是使用全集X中的p个元素作为测试集，然后剩下的n-p个元素作为训练集。根据数学上的定理可以得到，p个元素的选择方法有n!/((n-p)!p!)个，其中n!表示n的阶乘。在这个意义下，留p验证的时间复杂度也是非常高的。当p=1的时候，留1验证（Leave-one-out Cross Validation）的复杂度恰好是n。

\item 不彻底的交叉验证（Non-exhaustive Cross Validation）
不彻底的交叉验证不需要考虑全集X的所有划分情况，这种方法是留p验证的一个近似验证算法。

\item k-fold交叉验证（K-fold Cross Validation）
在k-fold交叉验证中，全集X被随机的划分成k个同等大小的集合A1,...,Ak，并且|A1|=...=|Ak|。这里的|Ai|指的是集合Ai的元素个数，也就是集合的势。这个时候需要遍历i从1到k，把X\textbackslash{Ai}当作训练集合，Ai当作测试集合。根据模型的测试统计，可以得到Ai集合中测试错误的结果数量ni。如果全集X的势是n的话，可以得到该模型的错误率是E=(ni求和)/n.
为了提高模型的精确度，可以将k-fold交叉验证的上述步骤重复t次，每一次都是随机划分全集X。在t次测试中，会得到t个模型的错误率E1,...,Et。令e=(Ei求和)/t。这样该模型的错误率就是e。

注释：
一般来说，k=10的情况使用得最多。
当k=2的时候，也就是最简单的k-fold交叉验证，2-fold交叉验证。这个时候X是A1和A2的并集，首先A1当训练集并且A2当测试集，然后A2当训练集并且A1当测试集。2-fold交叉验证的好处就是训练集和测试集的势都非常大，每个数据要么在训练集中，要么在测试集中。
当k=n的时候，也就是n-fold交叉验证。这个时候就是上面所说的留一验证（Leave-one-out Cross Validation）。
\end{itemize}
综上所述，交叉验证（Cross Validation）的好处是可以从有限的数据中获得尽可能多的有效信息，从而可以从多个角度去学习样本，避免陷入局部的极值。在这个过程中，无论是训练样本还是测试样本都得到了尽可能多的学习。

一般模型的选择过程：
在了解了交叉验证的方法之后，可以来介绍一般模型的选择过程。通过采用不同的输入训练样本，来决定机器学习算法中包含的各个参数值，称作模型选择。下面伪代码表示了模型选择的一般流程。在这个算法中，最重要的就是第三个步骤中的误差评价。 
（1）准备候选的q个模型:M1,...,Mq。 
（2）对每个模型M1,...,Mq求解它的学习结果。 
（3）对每个学习结果的误差e1,...,eq进行计算。这里可以使用上面所说的k-fold交叉验证方法。 
（4）选择误差e1,...,eq最小的模型作为最终的模型。



交叉验证是一种用来评价一个统计分析的结果是否可以推广到一个独立的数据集上的技术。主要用于预测，即，想要估计一个预测模型的实际应用中的准确度。它是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析， 而其它子集则用来做后续对此分析的确认及验证。 

交叉验证的理论是由Seymour Geisser所开始的。 它对于防范testing hypotheses suggested by the data是非常重要的，特别是当后续的样本是危险、成本过高或不可能（uncomfortable science）去搜集。

一个交叉验证将样本数据集分成两个互补的子集，一个子集用于训练（分类器或模型）称为训练集（training set）；另一个子集用于验证（分类器或模型的）分析的有效性称为测试集（testing set）。利用测试集来测试训练得到的分类器或模型，以此作为分类器或模型的性能指标。

得到高度预测精确度和低的预测误差，是研究的期望。为了减少交叉验证结果的可变性，对一个样本数据集进行多次不同的划分，得到不同的互补子集，进行多次交叉验证。取多次验证的平均值作为验证结果。

在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。

\textbf{目的}
用交叉验证的目的是为了得到可靠稳定的模型。在建立PCR 或PLS 模型时，一个很重要的因素是取多少个主成分的问题？用cross validation 校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不在变小时的主成分数

交叉验证的目的：假设分类器或模型有一个或多个未知的参数，并且设这个训练器（模型）与已有样本数据集（训练数据集）匹配。训练的过程是指优化模型的参数，以使得分类器或模型能够尽可能的与训练数据集匹配。我们在同一数据集总体中，取一个独立的测试数据集。
\textbf{常见类型的交叉验证}
\begin{itemize}
\item 重复随机子抽样验证。
    \subitem 做法：将数据集随机的划分为训练集和测试集。对每一个划分，用训练集训练分类器或模型，用测试集评估预测的精确度。进行多次划分，用均值来表示效能。
    \subitem 优点：与k倍交叉验证相比，这种方法的与k无关。
    \subitem 缺点：有些数据可能从未做过训练或测试数据；而有些数据不止一次选为训练或测试数据。
\item 2、K倍交叉验证（K>=2）。
    \subitem 做法：将样本数据集随机划分为K个子集（一般是均分），将一个子集数据作为测试集，其余的K-1组子集作为训练集；将K个子集轮流作为测试集，重复上述过程，这样得到了K个分类器或模型，并利用测试集得到了K个分类器或模型的分类准确率。用K个分类准确率的平均值作为分类器或模型的性能指标。10-倍交叉证实是比较常用的。
    \subitem 优点：每一个样本数据都即被用作训练数据，也被用作测试数据。避免的过度学习和欠学习状态的发生，得到的结果比较具有说服力。
\item 3、留一法交叉验证。
    \subitem 做法：假设样本数据集中有N个样本数据。将每个样本单独作为测试集，其余N-1个样本作为训练集，这样得到了N个分类器或模型，用这N个分类器或模型的分类准确率的平均数作为此分类器的性能指标。
    \subitem 优点：每一个分类器或模型都是用几乎所有的样本来训练模型，最接近样本，这样评估所得的结果比较可靠。实验没有随机因素，整个过程是可重复的。
    \subitem 缺点：计算成本高，当N非常大时，计算耗时。
\end{itemize}

\textbf{训练集和测试集的选取}
\begin{itemize}
\item 1、训练集中样本数量要足够多，一般至少大于总样本数的50%。
\item 2、训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。（随机取样，可重复性差）
\end{itemize}

\textbf{Logistic Regression}

\ifx\mlbook\undefined
    \end{document}
\fi
