\ifx\mlbook\undefined
    \documentclass[10pt,a4paper]{ctexbook}
    \providecommand{\pathroot}{..}

    \usepackage[CJKbookmarks,colorlinks,linkcolor=red]{hyperref}
    \usepackage{geometry}
    \usepackage{amsmath}

    \geometry{left=3.0cm,right=3.0cm,top=2.5cm,bottom=2.5cm}
    \setmainfont{SimSun}
    \XeTeXlinebreaklocale "zh"
    \XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

    \begin{document}
    \setlength{\baselineskip}{20pt}
    \title{机器学习简介}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{Sep 18, 2017}
    \maketitle
    \tableofcontents
\fi

\chapter{绪论}
\section{发展历史}
从计算机发明之初，人们就希望它能够帮助甚至代替人类完成重复性劳作。利用巨大的存储空间和超高的运算速度，计算机已经可以非常轻易地完成一些对于人类非常困难，但对计算机相对简单的问题。比如，统计一本书中不同单词出现的次数，存储一个图书馆中所有的藏书，或是计算非常复杂的数学公式，都可以通过计算机解决。然后，一些人类通过直觉可以很快解决的问题，目前却很难通过计算机解决。这些问题包括自然语言处理、图像识别、语音识别，等等。而它们就是人工智能需要解决的问题。

计算机要像人类一样完成更多智能的工作，需要掌握关乎这个世界海量的知识。比如要实现汽车自动驾驶，计算机至少需要能够判断哪里是路，哪里是障碍物。这个对人类非常直观的东西，但对计算机却是相当困难的。路有水泥、沥青的，也有石子的甚至土路。这些不同材质铺成的路在计算机看来差距非常大。如果让计算机掌握这些人类看起来非常直观的尝试，对于人工智能的发展是一个巨大的挑战。很多早期的人工智能系统只能成功应用于相对特定的环境（specific domain），在这些特定环境下，计算机需要了解的知识很容易被严格并且完整的定义。例如，IBM的深蓝（Deep Blue）在1997年打败了国际象棋冠军卡斯帕罗夫。设计出下象棋软件是人工智能史上的重大成就，但其主要挑战不在于让计算机掌握国际象棋中的规则。国际象棋是一个特定的环境，在这个环境中，计算机只需要了解每一个棋子规定的行动范围和行动方法即可。虽然计算机早在1997年就可以击败国际象棋世界冠军，但是直到20年后的今天，让计算机实现大部分成年人都可以完成的汽车驾驶却依旧十分困难。

为了使计算机更多地掌握开放环境（open domain）下的知识，研究人员进行了很多尝试。其中一个影响力非常大的领域是知识图库（Ontology\footnote{知识图库Ontology有时又被称为Knowledge Graph。Knowledge Graph更多的是指代谷歌内部建立的知识图库，而Ontology更多指代的是知识图库这个学术领域}）。WordNet是在开放环境中建立的一个较大且有影响力的知识图库。WordNet是由普林斯顿大学（Princeton University）的George Armitage Miller教授和Christiane Fellbaum教授带领开发的，它将155287个单词整理为了117659个近义词集（synsets）。基于这些近义词集，WordNet进一步定义了近义词集之间的关系。比如同义词集``狗"属于同义词集``犬科动物"，他们之间存在种属关系（hypernyms/hyponyms）\footnote{更多关于WordNet的信息可以参考其官方网站：\url{https://wordnet.princeton.edu}}。除了WordNet，也有不少研究人员尝试将Wikipedia中的知识整理成知识图库。谷歌的知识图库就是基于Wikipedia创建的。

虽然使用知识图库可以让计算机很好地掌握人工定义的知识，但建立知识图库一方面需要花费大量的人力物力，另一方面可以通过知识图库方式定义的知识有限，不是所有的知识都可以明确地定义成计算机可以理解的固定格式。很大一部分无法明确定义的知识，就是人类的经验。比如我们需要判断一封邮件是否为垃圾邮件，会综合考虑邮件发出的地址、邮件的标题、邮件的内容以及邮件收件人的长度，等等。这是收到无数垃圾邮件的骚扰之后总结出来的经验。这个经验很难以固定的方式表达出来，而且不同人对垃圾邮件的判断也会不一样。如何让计算机可以跟人类一样从历史经验中获取新的知识呢？这就是机器学习需要解决的问题。

卡内基梅隆大学（Carnegie Mellon University）的Tom Michael Mitchell教授在1997年出版的书籍\emph{Machine Learning}\footnote{Mitchell T M, Carbonell J G, Michalski R S. Machine Learning[M]. McGraw-Hill, 2003.}中对机器学习进行过非常专业的定义，这个定义在学术界内被多次引用。在这本书中对机器学习的定义为``如果一个程序可以在任务T上，随着经验E的增加，效果P也可以随之增加，则称这个程序可以从经验中学习"。在垃圾邮件分类问题中，``一个程序"指的是需要用到的机器学习算法，比如逻辑回归算法；``任务T"是指区分垃圾邮件的任务；``经验E"为已经区分过是否为垃圾邮件的历史邮件，在监督式机器学习问题中，这也被称之为训练数据；``效果P"为机器学习算法在区分是否为垃圾邮件任务上的准确率。

在使用逻辑回归算法解决垃圾邮件分类问题时，会先从每一封邮件中抽取对分类结果可能有影响的因素，比如说上文提到的发邮件的地址、邮件的标题及收件人的长度，等等。每一个因素被称之为一个特征（feature）。逻辑回归算法可以从训练数据中计算出每个特征和预测结果的相关度。比如在垃圾邮件分类问题中，可能会发现如果一个邮件的收件人越多，那么邮件为垃圾邮件的概率也就越高。在对一封未知的邮件做判断时，逻辑回归算法会根据从这封邮件中抽取得到的每一个特征以及这些特征和垃圾邮件的相关度来判断这封邮件是否为垃圾邮件。

在大部分情况下，在训练数据达到一定数量之前，越多的训练数据可以使逻辑回归算法对未知邮件做出的判断越精准。也就是说逻辑回归算法可以根据训练数据（经验E）提高在垃圾邮件分类问题（任务T）中的正确率（效果P）。之所以说在大部分情况下，是因为逻辑回归算法的效果除了依赖于训练数据，也依赖于从训练数据中提取的特征。假设从邮件中抽取的特征只有邮件发送的时间，那么即使有再多的训练数据，逻辑回归算法也无法很好地利用。这是因为邮件发送的时间和邮件是否为垃圾邮件之间的关联不大，而逻辑回归算法无法从数据中习得更好的特征表达。这也是很多传统机器学习算法的一个共同的问题。

类似从邮件中提取特征，如何数字化地表达现实世界中的实体，一直是计算机科学中一个非常重要的问题。如果将图书馆中的图书名称存储为结构化的数据，比如存储在Excel表格中，那么可以非常容易地通过书名查询一本书是否在图书馆中。如果图书的书名都是存在非结构化的图片中，那么要完成书名查找任务的难度将大大增加。类似的道理，如何从实体中提取特征，对于很多传统机器学习算法的性能有巨大影响。同样的数据使用不同的表达方式会极大地影响解决问题的难度。一旦解决了数据表达和特征提取，很多人工智能任务也就解决了90\%。

然而，对很多机器学习问题来说，特征提取不是一件简单的事情。在一些复杂问题上，要通过人工的方式设计有效的特征集合，需要很多的时间和精力，有时甚至需要整个领域数十年的研究投入。例如，假设想从很多照片中识别汽车。现在已知的是汽车有轮子，所以希望在图片中抽取``图片中是否出现了轮子"这个特征。但实际上，要从图片的像素中描述一个轮子的模式是非常难的。虽然车轮的形状很简单，但在实际图片中，车轮上可能会有来自车身的阴影、金属车轴的反光，周围物品也可能会部分遮挡车轮。实际图片中各种不确定的因素让我们很难直接抽取这样的特征。

既然人工的方式无法很好的抽取实体中的特征，那么是否与自动的方式呢？答案是肯定的。深度学习解决的核心问题之一就是自动地将简单的特征组合成更加复杂的特征，并使用这些组合特征解决问题。深度学习是机器学习的一个分支，它除了可以学习特征和任务之间的关联之外，还能自动从简单特征中提取更加复杂的特征。图\ref{fig:deep_learning_vs_traditional}中展示了深度学习和传统机器学习在流程上的差异。如图\ref{fig:deep_learning_vs_traditional}所示，深度学习算法可以从数据中学习更加复杂的特征表达，使得最后一步权重学习变的更加简单且有效。

\begin{figure}[ht]
    \centering
    \includegraphics[height=3cm]{\pathroot/introduction/images/deep_learning_vs_traditional.png}
    \caption{传统机器学习和深度学习流程对比}
    \label{fig:deep_learning_vs_traditional}
\end{figure}

早期的深度学习收到了神经科学的启发，它们之间有非常密切的联系。科学家们在神经科学上的发现使得我们相信深度学习可以胜任很多人工智能的任务。神经科学家发现，如果将小白鼠的视觉神经连接到听觉中枢，一段时间之后小鼠可以习得使用听觉中枢``看"世界。这说明虽然哺乳动物大脑分为了很多区域，但这些区域的学习机制却是十分相似的。在这一假想得到验证之前，机器学习的研究者们通常会为不同的任务设计不同的算法。而且直到今天，学术机构的机器学习领域也被划分为了自然语言处理、计算机视觉和语音识别等不同的实验室。因为深度学习的通用性，深度学习的研究者往往可以跨越多个研究方向甚至同时活跃于所有的研究方向。

虽然深度学习领域的研究人员相比其他机器学习领域更多的收到了大脑工作原理的启发，而且媒体界也经常强调深度学习算法和大脑工作原理的相似性，但现代深度学习的发展不拘泥于模拟人脑神经元和人脑的工作机理。模拟人类大脑也不再是深度学习研究的主导方向。我们不应该认为深度学习是在试图模仿人类大脑。目前科学家对人类大脑学习机制的理解还不足以为当下的深度学习模型提供指导。

现代的深度学习已经超越了神经科学观点，它可以更广泛地适用于各种并不是由神经网络启发而来的机器学习框架。值得注意的是，有一个领域的研究者尝试从算法层理解大脑的工作机制，它不同于深度学习的领域，被称为``计算神经学"（computational neuroscience）。深度学习领域主要关注如何搭建智能的计算机系统，解决人工智能中遇到的问题。计算机神经学则主要关注如何建立更准确的模型来模拟人类大脑的工作。

总的来说，人工智能、机器学习和深度学习是非常相关的几个领域。图\ref{fig:AI_ML_DNN_relations}总结了它们之间的关系。人工智能是一类非常广泛的问题，机器学习是解决这类问题的一个重要手段。深度学习则是机器学习的一个分支。在很多人工智能问题上，深度学习的方法突破了传统机器学习方法的瓶颈，推动了人工智能领域的发展。

\begin{figure}[ht]
    \centering
    \includegraphics[height=5cm]{\pathroot/introduction/images/AI_ML_DNN_relations.png}
    \caption{传统机器学习和深度学习流程对比}
    \label{fig:AI_ML_DNN_relations}
\end{figure}


\section{机器学习与传统统计学}
传统上做统计的人面临的数据都是来自于自然科学里的数据，比如Fisher面临的农业数据，或者生物上的数据，或者物理上的数据。这些数据都有一个特点就是可以很好的符合传统的统计分布，如正态分布 泊松分布等。面临这个实际情况，做统计的人有一个根深蒂固的思维，就是统计是概率的反问题。认为统计的目标是找出生成统计数据背后的真实概率。这是传统上做统计的人的最核心思想，所以不管点估计也好，假设检验也好，大样本方法也好。所有的方法背后所隐含的思想就是数据一定是由某些概率分布生成的。

做机器学习的人有一部分来自于当年雄心勃勃研究人工智能而后承认现状转而研究一些实际问题的人，另一部分是互联网兴起之后实际中对数据预测有强烈需求的人。所以他们面临的数据来源完全不同于传统的做统计的人。最典型的机器学习的应用就是点击率预估、商品推荐。我们很难相信我们点开一家购物网站之后，我们就自动的对这个网站上所有的物品是否购买有一个概率分布。但是如果用传统的统计方法来做预测，这种假设就是天然的隐含的。所以面临这种实际情况，做机器学习的人必须找到其他看待数据方法。所以他们的观点是数据的几何结构才是在这种情况下看待数据的正确方法。那么自然而然的分类和聚类的手段就成了机器学习的人最得心应手的两种手段。

举个例子可以比较好的说明，就是PCA主成分分析。这个方法传统统计上就有，机器学习上也有。经典而简单。做统计的人，第一次看到PCA都是在多元统计分析里，那时候对PCA的解释是第一主成分是随机变量的线性组合，这个线性组合的方差是所有线性组合里方差最大的。请注意，此时看待数据的方式是概率的。做机器学习的人，他们看待PCA是，把样本数据先去掉均值。然后找K维子空间逼近样本数据，逼近最好的K维子空间的基就是我们要找的主成分。请注意，此时的观点完全是几何的。当然在目前各个学科交叉融合的情况下，双方都会采取不同的观点，上述说法并不是说做统计或者做机器学习的人都是采用一成不变的观点，这点明眼人心里有数就行，不必纠缠。对样本数据做主成分分析得出来每个主成分的特征值。众所周知，绝大部分特征值都是很接近于0的。这时候双方思维的一个主要区别就体现的比较明显，做机器学习的人从几何的观点，可以自然的认为，由于特征值太小这些维度看成噪声是很正常的可以去掉，而不影响样本的所包含的信息。但是做统计的人天然认为样本是某个分布生成的，所以由样本所生成的特征值自然是服从某一个分布的，那么特征值是不是0就要进行的参数估计和假设检验。这个对做机器学习的人来说绝对是然而并没有什么卵用的步骤。但对做统计的人来说这是他们思维的自然延伸。

所以双方最主要的区别就是看待数据生成方式。统计的人认为，数据由某个概率分布生成。机器学习的人认为数据是特征集到Label集的特征映射所生成的。统计的目标是恢复那个背后的概率，机器学习的目标是恢复特征映射。

最后我想说的是，上述对统计和机器学习的区别做了区别。但不代表做统计和做机器学习的人都是死板人，都以一成不变的方式看待问题。时代在进步。不管做什么的人都是会面临实际问题，采用多方观点。最终的目的是把问题解决掉而不是做一些无谓的争论。


\section{监督学习}
监督学习指的是人们给机器一大堆标记好的数据，比如一大堆照片，标记出哪些是猫的照片，哪些不是，然后让机器自己学习归纳出算法，可以判断出其他照片是否是猫。目前这个领域算法代表：Linear regression, Logistic regression, Neural network, SVM等等。 

分类问题和回归问题是监督学习的两大种类。

分类问题希望解决的是将不同的样本分到事先定义好的类别中。

与分类问题不同，回归问题解决的是对具体数值的预测。比如房价预测、销量预测等都是回归问题。这些问题需要预测的不是一个事先定义好的类别，而是一个任意实数。

\subsection{深度学习}
随着AlphaGo战胜李世石，人工智能和深度学习这些概念已经成为一个非常火的话题。谷歌（Google）、脸书（Facebook）、百度、阿里巴巴等一系列国内外大公司纷纷对外公开宣布了人工智能将作为他们下一个战略重心。在类似AlphaGo、无人驾驶汽车等最新技术的背后，深度学习是推动这些技术发展的核心力量。



\section{无监督学习}
非监督学习指的就是人们给机器一大堆没有标记的数据，让机器可以对数据进行分类、检测异常等。

\section{应用现状}
\section{概念介绍}

\begin{itemize}
\item 监督学习：利用一组已知类别的样本调整分类器的参数，\\使其达到所要求性能的过程
\item 一些符号定义：

$x^{(i)}$：指数据集中的第$i$个样本的特征类数据。

$y^{(i)}$：指数据集中的第$i$个样本的目标值。

$\left(x^{(i)},y^{(i)}\right)$：表示一个样本实例。

$\left\{\left(x^{(i)},y^{(i)}\right), i=1,...,N\right\}$：表示一个数据集。
\\例如，对于手写体识别来说，图片的像素表示即为特征$x$，图片表示的数字即为目标值$y$。

\end{itemize}

\begin{itemize}
\item 一个完整的有监督学习的开发流程：
\\(1) 获取数据，对数据做一些清洗、转换等操作。
\\(2) 将数据样本拆分成训练集、验证集和测试集。训练集用来训练模型，验证集用来评估模型效果和调参，测试集则用来评估最终的模型效果。
\\(3) 开发模型或直接使用开发好的模型工具，在训练集上进行训练。
\\(4) 获取训练好的模型，使用验证集评估其效果。如果没有达到预期，需要进一步对模型调参、获取新的特征等操作，直到满足训练效果为止。
\\(5) 使用训练好的模型，在测试集上评估其最终效果。
\end{itemize}

\textbf{交叉验证{\color{red} TODO}}

交叉验证（Cross Validation），有的时候也称作循环估计（Rotation Estimation），是一种统计学上将数据样本切割成较小子集的实用方法，该理论是由Seymour Geisser提出的。

在模式识别（Pattern Recognition）和机器学习（Machine Learning）的相关研究中，经常会将整个数据集合分成两个部分，分别是训练集合和测试集合。假设X是集合全体，A是全集X的非空真子集，那么非空集合X\textbackslash{A}则是集合A在全集X中的补集。于是可以先在A上面做训练和分析，而集合X\textbackslash{A}则用来做测试和验证。一开始的集合A被称作训练集，而它的补集X\textbackslash{A}被称作验证集或者测试集。这里有一个重要的观点就是：只有训练集才可以使用在模型的训练之中，而测试集必须在模型训练完成之后才被用来评估模型的误差。

\textbf{HoldOut检验（Hold-Out Method）}
这个方法是将原始的数据集合X随机分成两个集合A和X\textbackslash{A}，其中A作为训练集，X\textbackslash{A}作为测试集。先使用训练集训练模型，然后利用测试集验证模型的效果，记录最后的分类准确率作为Hold-Out下该模型的性能指标。比方说，处理时间序列模型是否准确的时候，把整个数据集合分成前后两部分，前部分占比70\%，后部分占比30\%。前部分来进行时间序列模型的训练，后部分用来测试改时间序列的准确性。其准确性可以用MAE，MAPE之类的统计指标来衡量。综上所述，该方法的好处就是处理起来简单，只需要把原始数据分成两个部分即可。但是从严格意义上来说，Hold-Out检验并不算是交叉检验（Cross Validation），因为该方法没有达到交叉检验的思想，而且最后验证准确性的高低和原始数组的分类有很大的关系，所以该方法得到的结果在某些场景中并不具备特别大的说服力。在Hold-Out检验不够有说服力的情形下，有人提出了交叉验证这一个重要思想。

\textbf{交叉检验的常见形式}
假设有一个未知模型有一个或者多个未知的参数，并且有一个训练集。操作的过程就是对该模型的参数进行调整，使得该模型能够最大的反映训练集的特征。如果模型因为训练集过小或者参数不合适而产生过度拟合的情况，测试集的测试效果就可以得到验证。交叉验证是一种能够预测模型拟合性能的有效方法。

\textbf{彻底的交叉验证（Exhaustive Cross Validation）}
彻底的交叉验证方法指的是遍历全集X的所有非空真子集A。换句话说也就是把A当作训练集，X\textbackslash{A}是测试集。如果X中有n个元素，那么非空真子集A的选择方法则是$2^{n}-2$，这个方法的时间复杂度是指数级别的。

\begin{itemize}
\item 留P验证（Leave-p-out Cross Validation)
留p验证（LpO CV）指的是使用全集X中的p个元素作为测试集，然后剩下的n-p个元素作为训练集。根据数学上的定理可以得到，p个元素的选择方法有n!/((n-p)!p!)个，其中n!表示n的阶乘。在这个意义下，留p验证的时间复杂度也是非常高的。当p=1的时候，留1验证（Leave-one-out Cross Validation）的复杂度恰好是n。

\item 不彻底的交叉验证（Non-exhaustive Cross Validation）
不彻底的交叉验证不需要考虑全集X的所有划分情况，这种方法是留p验证的一个近似验证算法。

\item k-fold交叉验证（K-fold Cross Validation）
在k-fold交叉验证中，全集X被随机的划分成k个同等大小的集合A1,...,Ak，并且|A1|=...=|Ak|。这里的|Ai|指的是集合Ai的元素个数，也就是集合的势。这个时候需要遍历i从1到k，把X\textbackslash{Ai}当作训练集合，Ai当作测试集合。根据模型的测试统计，可以得到Ai集合中测试错误的结果数量ni。如果全集X的势是n的话，可以得到该模型的错误率是E=(ni求和)/n.
为了提高模型的精确度，可以将k-fold交叉验证的上述步骤重复t次，每一次都是随机划分全集X。在t次测试中，会得到t个模型的错误率E1,...,Et。令e=(Ei求和)/t。这样该模型的错误率就是e。

注释：
一般来说，k=10的情况使用得最多。
当k=2的时候，也就是最简单的k-fold交叉验证，2-fold交叉验证。这个时候X是A1和A2的并集，首先A1当训练集并且A2当测试集，然后A2当训练集并且A1当测试集。2-fold交叉验证的好处就是训练集和测试集的势都非常大，每个数据要么在训练集中，要么在测试集中。
当k=n的时候，也就是n-fold交叉验证。这个时候就是上面所说的留一验证（Leave-one-out Cross Validation）。
\end{itemize}
综上所述，交叉验证（Cross Validation）的好处是可以从有限的数据中获得尽可能多的有效信息，从而可以从多个角度去学习样本，避免陷入局部的极值。在这个过程中，无论是训练样本还是测试样本都得到了尽可能多的学习。

一般模型的选择过程：
在了解了交叉验证的方法之后，可以来介绍一般模型的选择过程。通过采用不同的输入训练样本，来决定机器学习算法中包含的各个参数值，称作模型选择。下面伪代码表示了模型选择的一般流程。在这个算法中，最重要的就是第三个步骤中的误差评价。 
（1）准备候选的q个模型:M1,...,Mq。 
（2）对每个模型M1,...,Mq求解它的学习结果。 
（3）对每个学习结果的误差e1,...,eq进行计算。这里可以使用上面所说的k-fold交叉验证方法。 
（4）选择误差e1,...,eq最小的模型作为最终的模型。



交叉验证是一种用来评价一个统计分析的结果是否可以推广到一个独立的数据集上的技术。主要用于预测，即，想要估计一个预测模型的实际应用中的准确度。它是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析， 而其它子集则用来做后续对此分析的确认及验证。 

交叉验证的理论是由Seymour Geisser所开始的。 它对于防范testing hypotheses suggested by the data是非常重要的，特别是当后续的样本是危险、成本过高或不可能（uncomfortable science）去搜集。

一个交叉验证将样本数据集分成两个互补的子集，一个子集用于训练（分类器或模型）称为训练集（training set）；另一个子集用于验证（分类器或模型的）分析的有效性称为测试集（testing set）。利用测试集来测试训练得到的分类器或模型，以此作为分类器或模型的性能指标。

得到高度预测精确度和低的预测误差，是研究的期望。为了减少交叉验证结果的可变性，对一个样本数据集进行多次不同的划分，得到不同的互补子集，进行多次交叉验证。取多次验证的平均值作为验证结果。

在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。

\textbf{目的}
用交叉验证的目的是为了得到可靠稳定的模型。在建立PCR 或PLS 模型时，一个很重要的因素是取多少个主成分的问题？用cross validation 校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不在变小时的主成分数

交叉验证的目的：假设分类器或模型有一个或多个未知的参数，并且设这个训练器（模型）与已有样本数据集（训练数据集）匹配。训练的过程是指优化模型的参数，以使得分类器或模型能够尽可能的与训练数据集匹配。我们在同一数据集总体中，取一个独立的测试数据集。
\textbf{常见类型的交叉验证}
\begin{itemize}
\item 重复随机子抽样验证。
    \subitem 做法：将数据集随机的划分为训练集和测试集。对每一个划分，用训练集训练分类器或模型，用测试集评估预测的精确度。进行多次划分，用均值来表示效能。
    \subitem 优点：与k倍交叉验证相比，这种方法的与k无关。
    \subitem 缺点：有些数据可能从未做过训练或测试数据；而有些数据不止一次选为训练或测试数据。
\item 2、K倍交叉验证（K>=2）。
    \subitem 做法：将样本数据集随机划分为K个子集（一般是均分），将一个子集数据作为测试集，其余的K-1组子集作为训练集；将K个子集轮流作为测试集，重复上述过程，这样得到了K个分类器或模型，并利用测试集得到了K个分类器或模型的分类准确率。用K个分类准确率的平均值作为分类器或模型的性能指标。10-倍交叉证实是比较常用的。
    \subitem 优点：每一个样本数据都即被用作训练数据，也被用作测试数据。避免的过度学习和欠学习状态的发生，得到的结果比较具有说服力。
\item 3、留一法交叉验证。
    \subitem 做法：假设样本数据集中有N个样本数据。将每个样本单独作为测试集，其余N-1个样本作为训练集，这样得到了N个分类器或模型，用这N个分类器或模型的分类准确率的平均数作为此分类器的性能指标。
    \subitem 优点：每一个分类器或模型都是用几乎所有的样本来训练模型，最接近样本，这样评估所得的结果比较可靠。实验没有随机因素，整个过程是可重复的。
    \subitem 缺点：计算成本高，当N非常大时，计算耗时。
\end{itemize}

\textbf{训练集和测试集的选取}
\begin{itemize}
\item 1、训练集中样本数量要足够多，一般至少大于总样本数的50%。
\item 2、训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。（随机取样，可重复性差）
\end{itemize}


\section{训练集、验证集和测试集}
1.传统的机器学习领域中，由于收集到的数据量往往不多，比较小，所以需要将收集到的数据分为三类：训练集、验证集、测试集。也有人分为两类，就是不需要测试集。
比例根据经验不同而不同，这里给出一个例子，如果是三类，可能是训练集：验证集：测试集=6:2:2；如果是两类，可能是训练集：验证集=7:3。因为数据量不多，所以验证集和测试集需要占的数据比例比较多。
2.在大数据时代的机器学习或者深度学习领域中，如果还是按照传统的数据划分方式不是十分合理，因为测试集和验证集用于评估模型和选择模型，所需要的数据量和传统的数据量差不多，但是由于收集到的数据远远大于传统机器学习时代的数据量，所以占的比例也就要缩小。比如我们拥有1000000，这么多的数据，训练集：验证集：测试集=98:1:1。如果是两类，也就是相同的道理。

注意：有些人在把数据分类的时候是没有测试集数据，这样并不是十分合理，有测试集比较放心，建议把数据分类最好有这个数据集，也就是分为三类数据哈。



在有监督(supervise)的机器学习中，数据集常被分成2~3个，即：训练集(train set) 验证集(validation set) 测试集(test set)。

\url{http://blog.sina.com.cn/s/blog_4d2f6cf201000cjx.html}

一般需要将样本分成独立的三部分训练集(train set)，验证集(validation set)和测试集(test set)。其中训练集用来估计模型，验证集用来确定网络结构或者控制模型复杂程度的参数，而测试集则检验最终选择最优的模型的性能如何。一个典型的划分是训练集占总样本的50％，而其它各占25％，三部分都是从样本中随机抽取。
样本少的时候，上面的划分就不合适了。常用的是留少部分做测试集。然后对其余N个样本采用K折交叉验证法。就是将样本打乱，然后均匀分成K份，轮流选择其中K－1份训练，剩余的一份做验证，计算预测误差平方和，最后把K次的预测误差平方和再做平均作为选择最优模型结构的依据。特别的K取N，就是留一法（leave one out）。

http://www.cppblog.com/guijie/archive/2008/07/29/57407.html

这三个名词在机器学习领域的文章中极其常见，但很多人对他们的概念并不是特别清楚，尤其是后两个经常被人混用。Ripley, B.D（1996）在他的经典专著Pattern Recognition and Neural Networks中给出了这三个词的定义。
Training set: A set of examples used for learning, which is to fit the parameters \[i.e., weights\] of the classifier. 
Validation set: A set of examples used to tune the parameters \[i.e., architecture, not weights\] of a classifier, for example to choose the number of hidden units in a neural network. 
Test set: A set of examples used only to assess the performance \[generalization\] of a fully specified classifier.
显然，training set是用来训练模型或确定模型参数的，如ANN中权值等； validation set是用来做模型选择（model selection），即做模型的最终优化及确定的，如ANN的结构；而 test set则纯粹是为了测试已经训练好的模型的推广能力。当然，test set这并不能保证模型的正确性，他只是说相似的数据用此模型会得出相似的结果。但实际应用中，一般只将数据集分成两类，即training set 和test set，大多数文章并不涉及validation set。
Ripley还谈到了Why separate test and validation sets?
1. The error rate estimate of the final model on validation data will be biased (smaller than the true error rate) since the validation set is used to select the final model.
2. After assessing the final model with the test set, YOU MUST NOT tune the model any further.

http://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set

Step 1) Training: Each type of algorithm has its own parameter options (the number of layers in a Neural Network, the number of trees in a Random Forest, etc). For each of your algorithms, you must pick one option. That’s why you have a validation set.

Step 2) Validating: You now have a collection of algorithms. You must pick one algorithm. That’s why you have a test set. Most people pick the algorithm that performs best on the validation set (and that's ok). But, if you do not measure your top-performing algorithm’s error rate on the test set, and just go with its error rate on the validation set, then you have blindly mistaken the “best possible scenario” for the “most likely scenario.” That's a recipe for disaster.

Step 3) Testing: I suppose that if your algorithms did not have any parameters then you would not need a third step. In that case, your validation step would be your test step. Perhaps Matlab does not ask you for parameters or you have chosen not to use them and that is the source of your confusion.

My Idea is that those option in neural network toolbox is for avoiding overfitting. In this situation the weights are specified for the training data only and don't show the global trend. By having a validation set, the iterations are adaptable to where decreases in the training data error cause decreases in validation data and increases in validation data error; along with decreases in training data error, this demonstrates the overfitting phenomenon.

http://blog.sciencenet.cn/blog-397960-666113.html

http://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-networ

for each epoch
for each training data instance
propagate error through the network
adjust the weights
calculate the accuracy over training data
for each validation data instance
calculate the accuracy over the validation data
if the threshold validation accuracy is met
exit training
else
continue training

Once you're finished training, then you run against your testing set and verify that the accuracy is sufficient.

Training Set: this data set is used to adjust the weights on the neural network.

Validation Set: this data set is used to minimize overfitting. You're not adjusting the weights of the network with this data set, you're just verifying that any increase in accuracy over the training data set actually yields an increase in accuracy over a data set that has not been shown to the network before, or at least the network hasn't trained on it (i.e. validation data set). If the accuracy over the training data set increases, but the accuracy over then validation data set stays the same or decreases, then you're overfitting your neural network and you should stop training.

Testing Set: this data set is used only for testing the final solution in order to confirm the actual predictive power of the network.

Validating set is used in the process of training. Testing set is not. The Testing set allows

1)to see if the training set was enough and 
2)whether the validation set did the job of preventing overfitting. If you use the testing set in the process of training then it will be just another validation set and it won't show what happens when new data is feeded in the network.

Training set: A set of examples used for learning, that is to fit the parameters \[i.e., weights\] of the classifier.

Validation set: A set of examples used to tune the parameters \[i.e., architecture, not weights\] of a classifier, for example to choose the number of hidden units in a neural network.

Test set: A set of examples used only to assess the performance \[generalization\] of a fully specified classifier.

The error surface will be different for different sets of data from your data set (batch learning). Therefore if you find a very good local minima for your test set data, that may not be a very good point, and may be a very bad point in the surface generated by some other set of data for the same problem. Therefore you need to compute such a model which not only finds a good weight configuration for the training set but also should be able to predict new data (which is not in the training set) with good error. In other words the network should be able to generalize the examples so that it learns the data and does not simply remembers or loads the training set by overfitting the training data.

The validation data set is a set of data for the function you want to learn, which you are not directly using to train the network. You are training the network with a set of data which you call the training data set. If you are using gradient based algorithm to train the network then the error surface and the gradient at some point will completely depend on the training data set thus the training data set is being directly used to adjust the weights. To make sure you don't overfit the network you need to input the validation dataset to the network and check if the error is within some range. Because the validation set is not being using directly to adjust the weights of the netowork, therefore a good error for the validation and also the test set indicates that the network predicts well for the train set examples, also it is expected to perform well when new example are presented to the network which was not used in the training process.

Early stopping is a way to stop training. There are different variations available, the main outline is, both the train and the validation set errors are monitored, the train error decreases at each iteration (backprop and brothers) and at first the validation error decreases. The training is stopped at the moment the validation error starts to rise. The weight configuration at this point indicates a model, which predicts the training data well, as well as the data which is not seen by the network . But because the validation data actually affects the weight configuration indirectly to select the weight configuration. This is where the Test set comes in. This set of data is never used in the training process. Once a model is selected based on the validation set, the test set data is applied on the network model and the error for this set is found. This error is a representative of the error which we can expect from absolutely new data for the same problem.

\section{泛化能力}
\subsection{泛化误差}
学习方法的泛化能力（generalizaiton ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的方法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的，很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析。

首先给出泛化误差的定义。如果学到的模型是$\hat{f}$，那么用这个模型对未知数据预测的误差即为泛化误差（generalizaiton error）
\[
R_{exp}(\hat{f})=E_{p}[L(Y, \hat{f}(X))]=\int_{\chi\times\gamma}{L(y,\hat{f}(x))P(x,y)dxdy}
\]

泛化误差反映了学习方法的泛化能力，如果一种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险。

\subsection{泛化误差上界}



\section{一文读懂机器学习、数据科学、人工智能、深度学习和统计学之间的区别}

在这篇文章中，数据科学家与分析师 VincentGranville 明晰了数据科学家所具有的不同角色，以及数据科学与机器学习、深度学习、人工智能、统计学、物联网、运筹学和应用数学等相关领域的比较和重叠。Granville 介绍说，由于数据科学是一个范围很广的学科，所以他首先介绍了在业务环境中可能会遇到的数据科学家的类型：你甚至可能会发现你自己原来也是某种数据科学家。和其它任何科学学科一样，数据科学也可能会从其它相关学科借用技术；当然，我们也已经开发出了自己的技术库，尤其是让我们可以以自动化的方式（甚至完全无需人类干预）处理非常大规模的非结构化数据集的技术和算法，进而实时执行交易或进行预测。

1. 数据科学家具有哪些不同类型？

要更详细地了解数据科学家的类型，可参阅文章： \href{http://suo.im/28rlX1}{Six categories of Data Scientists}和\href{http://suo.im/3NNUpd}{16 analytic disciplines compared to datascience}


。更多有用的信息可参阅：

\href{http://suo.im/4bRkRG}{数据科学家与数据架构师}
\href{http://suo.im/3mpo6E}{数据科学家与数据工程师}
\href{http://suo.im/2GGtfG}{数据科学家与统计学家}
\href{http://suo.im/3h0hkX}{数据科学家与业务分析师}


而在最近，数据科学家 Ajit Jaokar 则又讨论了 A 型数据科学家（分析师）和 B 型数据科学家（建造者）之间的区别：

A 型数据科学家能够很好地编写操作数据的代码，但并不一定是一个专家。A 型数据科学家可能是一个实验设计、预测、建模、统计推理或统计学方面的事情的专家。然而总体而言，一个数据科学家的工作产品并不是「P 值和置信区间」——就像学术界的统计学有时候建议的那样（而且这常常是为传统的制药等等行业工作的）。在谷歌，A 型数据科学家被称为统计学家、定量分析师、决策支持工程开发分析师，也有一些被称为数据科学家。

B 型数据科学家：这里的 B 是指 Building。B 型数据科学家和 A 型数据科学家具有相同的背景，但他们还是很强的程序员、甚至经验丰富的软件工程师。B 型数据科学家主要关注在生产环境中使用数据。他们构建能与用户进行交互的模型，通常是提供推荐（产品、可能认识的人、广告、电影、搜索结果等）。

而对于业务处理优化，我也有自己的看法，我将其分成了 ABCD 四个方向，其中 A 表示分析科学（analytics science），B 表示业务科学（business science），C 表示计算机科学（computer science），D 则表示数据科学（data science）。数据科学可能会涉及到编程或数学实践，但也可能不会涉及到。你可以参考

\href{http://suo.im/11bR7o}{High versus low-level data science}

这篇文章了解高端和低端的数据科学的差异。在一家创业公司，数据科学家通常要做很多类型的工作，其扮演的工作角色可能包括：执行、数据挖掘师、数据工程师或架构师、研究员、统计学家、建模师（做预测建模等等）和开发人员。

虽然数据科学家常常被看作是经验丰富的 R、Python、SQL、Hadoop 程序员，而且精通统计学，但这不只不过是冰山一角而已——人们对于数据科学家的这些看法不过是来自于重在教授数据科学的部分元素的数据培训项目而已。但正如一位实验室技术人员也可以称自己为物理学家一样，真正的物理学家远不止于此，而且他们的专业领域也是非常多样化的：天文学、数学物理、核物理、力学、电气工程、信号处理（这也是数据科学的一个领域）等等许多。数据科学也是一样，包含的领域有：生物信息学、信息技术、模拟和量化控制、计算金融、流行病学、工业工程、甚至数论。

对我而言，在过去的十年里，我专注于机器到机器和设备到设备的通信、开发能自动处理大型数据集的系统、执行自动化交易（比如购买网络流量或自动生成内容）。这意味着需要开发能够处理非结构化数据的算法，这也是人工智能、物联网和数据科学的交叉领域，也可被称为深度数据科学（deep data science）。其对数学的需求相对较少，也只涉及到较少的编程（大部分是调用 API），但其却是相当数据密集型的（包括构建数据系统），并且基于专门为此背景而设计的全新统计技术。

在此之前，我的工作是实时的信用卡欺诈检测。在我事业的早期阶段（大约 1990 年），我开发过图像远程感知技术，其中包括识别卫星图像的模式（形状和特征，比如湖泊）和执行图像分割：那段时间我的研究工作被称为是计算统计学，但在我的母校，隔壁的计算机科学系也在做着几乎完全一样的事情，但他们把自己的工作叫做是人工智能。

今天，这项工作被称作数据科学或人工智能，其子领域包括信号处理、用于物联网的计算机视觉等。

另外，数据科学家也可以在各种各样的数据科学项目中出现，比如数据收集阶段或数据探索阶段一直到统计建模和已有系统维护。

2. 机器学习对比深度学习

在深入探讨数据学习与机器学习之间的区别前，我们先简单讨论下机器学习与深度学习的区别。机器学习一系列在数据集上进行训练的算法，来做出预测或采取形同从而对系统进行优化。例如，基于历史数据，监督分类算法就被用来分类潜在的客户或贷款意向。根据给定任务的不同（例如，监督式聚类），用到的技术也不同：朴素贝叶斯、支持向量机、神经网络、ensembles、关联规则、决策树、逻辑回归或多种方法之间的结合。

这些都是数据科学的分支。当这些算法被用于自动化的时候，就像在自动飞行或无人驾驶汽车中，它被称为人工智能，更具体的细说，就是深度学习。如果数据收集自传感器，通过互联网进行传输，那就是机器学习或数据科学或深度学习应用到了 IoT 上。

有些人对深度学习有不同的定义。他们认为深度学习是带有更多层的神经网络（神经网络是一种机器学习技术）。深度学习与机器学习的区别这一问题在 Quora 上也被问到过，下面对此有详细的解释：

人工智能是计算机科学的一个子领域，创造于 20 世纪 60 年代，它涉及到解决对人类而言简单却对计算机很难的任务。详细来说，所谓的强人工智能系统应该是能做人类所能做的任何事。这是相当通用的，包含所有的任务，比如规划、到处移动、识别物体与声音、说话、翻译、完成社会或商业事务、创造性的工作（绘画、作诗）等。
自然语言处理只是人工智能与语言有关的一部分。
机器学习被认为是人工智能的一方面：给定一些可用离散术语（例如，在一些行为中，那个行为是正确的）描述的人工智能问题，并给出关于这个世界的大量信息，在没有程序员进行编程的情况下弄清楚「正确」的行为。典型的是，需要一些外部流程判断行为是否正确。在数学术语中，也就是函数：馈入输入，产生正确的输出。所以整个问题就是以自动化的方式建立该数学函数的模型。在二者进行区分时：如果我写出的程序聪明到表现出人类行为，它就是人工智能。但如果它的参数不是自动从数据进行学习，它就不是机器学习。
深度学习是如今非常流行的一种机器学习。它涉及到一种特殊类型的数学模型，可认为它是特定类型的简单模块的结合（函数结合），这些模块可被调整从而更好的预测最终输出。
3.机器学习与统计学之间的区别

《Machine Learning Vs.Statistics》这篇文章试图解答这个问题。这篇文章的作者认为统计学是带有置信区间（confidenceintervals）的机器学习，是为了预测或估计数量。但我不同意，我曾建立过不需要任何数学或统计知识的工程友好的置信区间。

4. 数据科学对比机器学习

机器学习和统计学都是数据科学的一部分。机器学习中的学习一词表示算法依赖于一些数据（被用作训练集），来调整模型或算法的参数。这包含了许多的技术，比如回归、朴素贝叶斯或监督聚类。但不是所有的技术都适合机器学习。例如有一种统计和数据科学技术就不适合——无监督聚类，该技术是在没有任何先验知识或训练集的情况下检测 cluster 和 cluster 结构，从而帮助分类算法。这种情况需要人来标记 cluster。一些技术是混合的，比如半监督分类。一些模式检测或密度评估技术适合机器学习。

数据科学要比机器学习广泛。数据科学中的数据可能并非来自机器或机器处理（调查数据可能就是手动收集，临床试验涉及到专业类型的小数据），就像我刚才所说的，它可能与「学习」没有任何关系。但主要的区别在于数据科学覆盖整个数据处理，并非只是算法的或统计类分支。细说之，数据科学也包括：

数据集成（data integration）
分布式架构（distributed architecture）
自动机器学习（automating machine learning）
数据可视化（data visualization）
dashboards 和 BI
数据工程（data engineering）
产品模式中的部署（deployment in production mode）
自动的、数据驱动的决策（automated, data-driven decisions）
当然，在许多公司内数据科学家只专注这些流程中的一个。

对于这篇文章，技术顾问 Suresh Babu 给出了一个评论，机器之心将其编译整合到了下面：

这篇文章说明了解使用机器/计算机来处理类似人类决策的任务的统计学习的基本术语是件很麻烦的事。

但文章中「当这些算法被用于自动化的时候，就像在自动飞行或无人驾驶汽车中，它被称为人工智能，更具体的细说，就是深度学习。」这样的说话看起来却有些随意任性。

当过去计算机/机器还不够友好，没有得到广泛使用的时候，统计学家和数据科学家的工作和现在这个领域的工作有很大的不同。比如说，当制造业开始使用计算机辅助后，生产速度和量都发生了巨大的变化——但它仍然是制造业。用制造机器来做原本人类做的程序化工作的想法最早来自 19 世纪初 Jacquard 和 Bouchon 等人。而 Jacquard 织布机的工作方式和现在计算机控制的织布机的工作方式基本相同。

现在的数据科学是一个知识体系，囊括了统计学和计算方法等等（而且在不同的具体领域不同学科的比例也不一样）。

机器学习（或使用了其它的术语，比如深度学习、认知计算）是让机器像人类一样思考和推理，基本上而言是指通过人工的方法（所以也叫人工智能）来代替人类天生的自然智能——涉及到的任务从简单到复杂都有。比如，无人驾驶汽车（目前）正在模仿人类的驾驶，驾驶条件也是人类在自然情况下会遇到的——我说「目前」是因为也许未来人类将很少能够直接驾驶机器，「驾驶（drive）」这个词本身都可能会改变含义。

这个领域里面也有些滑稽可笑的事情，比如一些基本的东西（比如一个下国际象棋或围棋的算法）被认为可以解释人脑的工作方式。就我们目前的知识水平而言，光是解释鸟或鱼的大脑的工作方式就已经非常困难了——这说明我们还没有真正理解学习的机制。为什么果蝇只需几百个神经元就能做到这么多事情？这还是神经科学的一个未解之谜。而认知是什么以及其在自然环境下是如何工作的也是一个数据科学傲慢地认为自己能解决的重大难题。（不管怎样，降维是一种无监督学习的方法。）

在很多方面，工具以及我们使用工具所做的事情自人类诞生以来就在引导着人类的学习。但这就扯远了。

\section{待整理资料}

\href{http://www.cnblogs.com/hellochennan/p/5423740.html}{让我们从机器学习谈起}




\ifx\mlbook\undefined
    \end{document}
\fi
