\ifx\mlbook\undefined
    \documentclass[10pt,a4paper]{ctexbook}
    \providecommand{\pathroot}{../..}

    \usepackage[CJKbookmarks,colorlinks,linkcolor=red]{hyperref}
    \usepackage{geometry}
    \usepackage{amsmath}
    \usepackage{minted}

    \geometry{left=3.0cm,right=3.0cm,top=2.5cm,bottom=2.5cm}
    \setmainfont{SimSun}
    \XeTeXlinebreaklocale "zh"
    \XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

    \begin{document}
    \setlength{\baselineskip}{20pt}
    \title{Logistic回归}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{Sep 8, 2017}
    %\maketitle
    \tableofcontents
\fi

\chapter{Logistic回归}

\section{广义线性模型}

\href{http://blog.csdn.net/acdreamers/article/details/44663091}{广义线性模型}


\section{岭回归和LASSO}
如果数据集的特征比样本点还多（$X_{N \times d}, d>N$）怎么办？是否还可以使用线性回归来做预测？答案是否定的，因为在计算 $(X^{T}X)^{-1}$ 的时候会出错。

为了解决这个问题，统计学家引入了岭回归（ridge regression）的概念。简单说来，岭回归就是在矩阵$X^{T}X$上加一个$\lambda I$使得矩阵非奇异，进而能对 $X^{T}X+\lambda I$求逆。在这种情况下，回归系数的计算公式变为：
\[
w=(X^{T}X+\lambda I)^{-1}X^{T}y
\]
岭回归最先用来处理特征数多于样本数的情况，现在也用于在估计中加入偏差，从而得到更好的估计。这里通过引入$\lambda$限制了所有$w$之和，通过引入该惩罚项，能够减少不重要的参数。这个技术在统计学上也叫作缩减（shrinkage）。

不难证明，在增加如下约束时，普通的最小二乘法回归会得到与岭回归一样的公式： 
\[
\left\|w\right\|^{2} = \sum\limits_{i=1}^{d}{w_{i}^{2}} \le \lambda
\]

上式限定了所有回归系数的平方和（二范数的平方）不能大于$\lambda$，使用普通的最小二乘法回归（线性回归）在当两个或更多的特征相关时，可能会得出一个很大的正系数和一个很大的负系数（回归系数）。正是因为上述限制的存在，使用岭回归可以避免这个问题。

与岭回归类似，另一个缩减（Shrinkage）LASSO 也对回归系数做了限定，对应的约束条件如下： 
\[
\left\|w\right\|_{1}=\sum\limits_{i=1}^{d}{|w_{i}|} \le \lambda
\]
唯一的不同点在于，这个约束条件使用绝对值取代了平方和。虽然约束形式只是稍作变化，结果却大相径庭：当$\lambda$足够小的时候，一些系数会因此缩减到0。

\subsection{What's the difference between one hot encoding and dummy encoding?}
Hi everyone,
There are two ways to encode categorical variables. One hot encoding and dummy encoding. I'm studied statistics and we always used dummy encoding because we don't want to see multicollinearity (dummy variable trap). Now I'm following the Kaggle competitions and everyone is using one hot enc. I'm not a "traditional" statistician (so I don't say dummy is the true one or something like that) but I'm just trying to understand why.
thanks in advance!

Dummy variable coding and one-hot encoding are exactly the same thing; the former term comes from statistics and the latter from computer science (borrowed from electronics).
The dummy variable trap can happen regardless of what you call the technique, although it tends to be less of a concern in ML because (a) multicollinearity is only a big issue in linear regression, and can be minimized with regularization, and (b) in statistics, the aim is to determine the coefficients; in ML, it's to determine the predictions, so even if the coefficients are being warped by multicollinearity, it's of secondary concern.




在很多机器学习任务中，特征并不总是连续值，而有可能是分类值。

例如，考虑一下的三个特征：

["male", "female"]

["from Europe", "from US", "from Asia"]

["uses Firefox", "uses Chrome", "uses Safari", "uses Internet Explorer"]
如果将上述特征用数字表示，效率会高很多。例如：
["male", "from US", "uses Internet Explorer"] 表示为[0, 1, 3]
["female", "from Asia", "uses Chrome"]表示为[1, 2, 1]
但是，即使转化为数字表示后，上述数据也不能直接用在我们的分类器中。因为，分类器往往默认数据数据是连续的，并且是有序的。但是，按照我们上述的表示，数字并不是有序的，而是随机分配的。

独热编码
为了解决上述问题，其中一种可能的解决方法是采用独热编码（One-Hot Encoding）。

独热编码即 One-Hot 编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。
例如：

自然状态码为：000,001,010,011,100,101
独热编码为：000001,000010,000100,001000,010000,100000

可以这样理解，对于每一个特征，如果它有m个可能值，那么经过独热编码后，就变成了m个二元特征。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。
这样做的好处主要有：

解决了分类器不好处理属性数据的问题

在一定程度上也起到了扩充特征的作用

举例
我们基于python和Scikit-learn写一个简单的例子：

from sklearn import preprocessing
enc = preprocessing.OneHotEncoder()

enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])

enc.transform([[0, 1, 3]]).toarray()
输出结果：
array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])







能否解释一下dummy encoding和one-hot encoding的具体使用和对自由度的影响？
在做regression的时候，经常会有多个categorical变量。可以用dummy encoding和one-hot encoding来处理。简单来说，dummy encoding就是把一个有h个level的变量变成h-1个变量，比如3个level的变量就表示成成10，01，或00。而one-hot encoding就是用h个变量来代表这h个level，比如3个level的变量就表示成100，010，001。


现在假设一共有3个categorical变量，每个变量都有4个level。现在需要建立regression。如果用dummy的话，就转换成3*4-4=8个变量，外加一个intercept。如果用one-hot的话，就转换成3*4=12个变量，不加intercept（防止dummy variable trap）。以上是我个人的理解，有错误的话请指正。

那这样的话，两种方法产生的最终输入变量数量不同，这会影响最终的degree of freedom吗？




如果你不使用regularization，那么one-hot encoding的模型会有多余的自由度。这个自由度体现在你可以把某一个分类型变量各个值对应的权重都增加某一数值，同时把另一个分类型变量各个值对应的权重都减小某一数值，而模型不变。在dummy encoding中，这些多余的自由度都被统摄到intercept里去了。这么看来，dummy encoding更好一些。如果你使用regularization，那么regularization就能够处理这些多余的自由度。此时，我觉得用one-hot encoding更好，因为每个分类型变量的各个值的地位就是对等的了。


很有启发，是不是可以这么理解：
以线性模型举例， 分类超平面是 wx+b =0，dummy下的话 w 有唯一解，one-hot 下 w 有无穷解 (就是答主说的 一部分权重增加点，另一部分权重减少点)，这样每个变量的权重就没有解释意义了，也使得模型没有真正的预测效果。加了正则化之后，相当于约束了 w 的解空间，使得 w 相对有意义



考虑一个极端情况，最简单的，单个连续变量的线性回归，。这里 x 虽然是连续变量，但也不能阻止我们故意用 one-hot encoding 来表示它。比如，假设输入数据 x 一共包含 n 个数，那可以把这 n 个数表达为 n x n 的单位矩阵。这样的话，显然可以直接精确拟合输入的 y，也就是过拟合了。本来只有 a 和 b 两个参数，现在变成了 n 或 n+1 个参数。自由度的增多伴随着的是参数的增多，所以更容易过拟合。继续这个假想的例子，为了减少过拟合，我们可以减少 one-hot encoding 的自由度个数，换言之，我们不用 n * n 矩阵，而用较小的矩阵；这样就会导致不同的 x 的值对应相同的编码。这样做实际上是在用分段常数函数来拟合。还是这个例子，我们也可以故意忘记 输入数据 x 的真实值，而把它们排序后用 1 到 n 的序号来代替，然后试图拟合这些序号与 y 之间的关系。这相当于对 x 做了一个奇怪的单调的非线性变换。但我们可以预期，虽然这么做会让本来的 x 与 y 的线性关系变成一种很别扭的关系，但一般不至于导致过拟合。



独热码，在英文文献中称做 one-hot code, 直观来说就是有多少个状态就有多少比特，而且只有一个比特为1，其他全为0的一种码制。通常，在通信网络协议栈中，使用八位或者十六位状态的独热码，且系统占用其中一个状态码，余下的可以供用户使用。

例如，有6个状态的独热码状态编码为：000001，000010，000100，001000，010000，100000。
再如，有十六个状态的独热码状态编码应该是：0000000000000001，0000000000000010，0000000000000100，0000000000001000，0000000000010000，0000000000100000 ，……，10000000000000000。但是通常我们为了方便书写，将二进制简化为十六进制表示(从右往左每四位二进制位用一位十六进制数表示)，那么，以上十六状态的独热码可以表示成0x0001, 0x0002, 0x0004, 0x0008, 0x0010, 0x0020, ……, 0x8000（其中的0x是十六进制的前缀表示，在诸如PLC等程序中也有其他表示方法）。



\section{线性回归}
\textbf{\large{一道简单的数学题: }}

Q：某小区成交了3套房子，其面积和对应的售价分别是：60平米、360万；80平米、400万；90平米、500万；现在有一套房子是70平米，预测它会卖多少钱？
\begin{itemize}
\item \textbf{模型假设}：$y=ax$，$房屋售价=a * 房屋面积$
\item \textbf{模型假设}：损失函数（让预测值与真实值的平方误差最小）：
\begin{align*}
f(a)&=\sum\limits_{i}{(y_{i}-p_{i})^2} =\sum\limits_{t}{(ax_{i}-p_{i})^2} \\
    &=(60a-360)^2+(80a-400)^2+(90a-500)^2=18100a^{2}-197200a+539600
\end{align*}
\item \textbf{求解令函数f(a) 取得最小值的解}：$a=5.448$
\item \textbf{预测}：$y=5.448*x=5.448*70=381.36$万 
\end{itemize}

\begin{itemize}
\item 模型=表示（Hypothesis）+评价（Cost Function）+优化（Solver）
\item 实际的机器学习模型与数学题的区别（1）
\subitem 更多形式的假设函数
\subsubitem 线性回归模型：$y=ax_{1}+bx_{2}+cx_{3}+\cdots$
\subsubitem 逻辑回归模型：
\[
y=\frac{1}{1 + e^{-(ax_{1}+bx_{2}+cx_{3}+\cdots)}}
\]
\subsubitem 深度神经网络：
\begin{align*}
&y=softmax{(az_{1}+bz_{2}+cz_{3}+\cdots)} \\
&h_{i}=\tanh{(w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{3}+\cdots)}
\end{align*}
\end{itemize}

\section{Logistic Regression}
这一章用来介绍常用的线性模型，主要包括：多元线性回归、Logistic回归（LR）。

\href{http://www.cs.cmu.edu/~sgopal1/papers/ICML13.pdf}{Distributed Training of Large-scale Logistic models}

\subsection{sigmoid函数}
sigmoid函数是常用的数学函数之一，它的数学表达式为
\[
    h_{\theta}(x)=g({\theta}^Tx)={\frac {1}{1+e^{-\theta^Tx}}}
\]
数学图像如图\ref{fig:sigmoid}所示。

\begin{figure}[ht]
    \centering
    \includegraphics[height=7cm]{\pathroot/theory/GLM/images/sigmoid.png}
    \caption{sigmoid函数}
    \label{fig:sigmoid}
\end{figure}

函数可导：
\[
g'(z)={\frac {d}{dz}}{\frac {1}{1+e^{-\theta^Tx}}}=\lim_{{\Delta x}\to 0}{\frac {f(x+{\Delta x})-f(x)}{\Delta x}}
\]

对于一个二分类问题，可假设$h_{\theta}(x)$为其中一类的概率，即：
\[
P(y=1|x;\theta)=h_{\theta}(x)
               =h_{\theta}(x)^{1}(1-h_{\theta}(x))^{1-1}
               =h_{\theta}(x)^{y}(1-h_{\theta}(x))^{1-y}
\]

\[
P(y=0|x;\theta)=1-h_{\theta}(x)
               =h_{\theta}(x)^{0}(1-h_{\theta}(x))^{1-0}
               =h_{\theta}(x)^{y}(1-h_{\theta}(x))^{1-y}
\]


\begin{minted}[mathescape,
               numbersep=5pt,
               frame=lines,
               framesep=2mm]{python}
class SimpleLogisticRegression(object):
    def __init__(self, alpha, feature_num):
        pass
    def fit(self, X, y, verbose=False):
        last_target = -sys.maxint
        last_step = 0
        step = 0
        while True:
            step += 1
            # 计算梯度并更新参数
            target = sum(map(lambda py, ty: ty * math.log(py) + (1 - ty) * math.log(1 - py),
                             map(self.__sigmoid, X), y)) / len(X)
            if target - last_target > 1e-8:
                last_target = target
                last_step = step
            elif step - last_step >= 10:
                break
        target = sum(map(lambda py, ty: ty * math.log(py) + (1 - ty) * math.log(1 - py),
                         map(self.__sigmoid, X), y)) / len(X)
        return target


    def predict(self, X):
        pass
    def __sigmoid(self, x):
        pass
    def _check_columns(self, X):
        pass

if __name__ == "__main__":
    lr = SimpleLogisticRegression(0.1, 3)
    X = [[1, 3, 5], [2, 4, 6], [3, 5, 7], [4,  6, 8]]
    y = [0, 0, 1, 1]
    print lr.predict(X)
    lr.fit(X, y, verbose=True)
    print lr.predict(X)
\end{minted}

\begin{minted}[mathescape,
               numbersep=5pt,
               frame=lines,
               framesep=2mm]{python}
#coding: utf-8
#author: Ryan
"""
A simple Logistic Regression model.
"""
from __future__ import division
import sys
import os
import random
import math
import collections
import array
import operator

class SimpleLogisticRegression(object):
    def __init__(self, alpha, feature_num):
        """构造函数
        参数
        ---
        alpha: double
            学习率
        feature_num: int
            特征数量
        """
        self.__alpha = alpha
        self.__features_num = feature_num
        self.__coef = [0.] * self.__features_num
        self.__intercept = 0.

    def fit(self, X, y, verbose=False):
        """训练模型。
        返回值
        ------
            模型训练的最终log似然值。
        """
        last_target = -sys.maxint
        last_step = 0
        step = 0
        while True:
            step += 1
            gradient = [0.] * (self.__features_num + 1)
            for tx, ty in zip(X, y):
                delta = ty - self.__sigmoid(tx)
                for i, xi in enumerate(tx):
                    gradient[i] += delta * xi
                gradient[-1] += delta
            gradient = map(lambda g: g / len(X), gradient)

            self.__coef = map(lambda c, g: c + self.__alpha * g, self.__coef, gradient[:-1])
            self.__intercept += self.__alpha * gradient[-1]

            target = sum(map(lambda py, ty: ty * math.log(py) + (1 - ty) * math.log(1 - py),
                             map(self.__sigmoid, X), y)) / len(X)
            if target - last_target > 1e-8:
                last_target = target
                last_step = step
            elif step - last_step >= 10:
                break
            if verbose is True and step % 1000 == 0:
                sys.stderr.write("step %s: %.6f\n" % (step, target))
        target = sum(map(lambda py, ty: ty * math.log(py) + (1 - ty) * math.log(1 - py),
                         map(self.__sigmoid, X), y)) / len(X)
        if verbose is True:
            sys.stderr.write("Final training error: %.6f\n" % (target))
        return target

    def predict(self, X):
        """输出每个样本的预测值。
        返回值
        -----
            列表类型，长度与X的样本量相同。
        """
        if not self._check_columns(X):
            sys.stderr.write("The data to be evaluated can't match training data's features\n")
            return None
        return map(self.__sigmoid, X)

    def __sigmoid(self, x):
        """sigmoid函数，返回sigmoid函数值"""
        return 1. / (1 + math.exp(-sum(map(operator.mul, self.__coef, x)) - self.__intercept))

    def _check_columns(self, X):
        """检查每个样本的类型是否是数组或者列表类型，并且长度与特征数相等。
        返回值
        -----
            数据合法时，返回True，否则返回False。
        """
        for x in X:
            if not isinstance(x, (list, tuple, array.array)):
                return False
            if len(x) != self.__features_num:
                return False
        return True

if __name__ == "__main__":
    lr = SimpleLogisticRegression(0.1, 3)
    X = [[1, 3, 5], [2, 4, 6], [3, 5, 7], [4,  6, 8]]
    y = [0, 0, 1, 1]
    print lr.predict(X)
    lr.fit(X, y, verbose=True)
    print lr.predict(X)
\end{minted}



\begin{itemize}
\item 更简洁的形式： $P(y|x;\theta)={h_{\theta}(x)}^y(1-h_{\theta}(x))^{1-y}$
\item 假设$m$个训练样本独立，则样本集在参数${\theta}$给定下，出现的概率为
\begin{align*}
L(\theta)&=p(\vec y|X;\theta)\\
         &=\prod_{i=1}^{m}{p(y^{(i)} | x^{(i)};\theta)}\\
         &=\prod_{i=1}^{m}{(h_{\theta}(x^{(i)}))^{y^{(i)}}(1-h_{\theta}(x^{(i)}))^{(1-y^{(i)})}}
\end{align*}

\item 我们希望最大化概率$L({\theta})$，也即最大化log似然值:

\item 最大化一个目标值，可采用梯度上升法，沿着梯度方向不断迭代。梯度求解如下：

\item 随机梯度下降法求解：
\subitem ${\theta}_{j}:={\theta}_{j}+{\alpha}(y^{(i)}-h_{\theta}(x^{(i)}))x_{j}^{(i)}$

\item 思考：
\subitem 如果引入$L1$正则、$L2$正则，那么梯度又该怎么求解呢？
\subitem LR的梯度求解公式与线性回归的梯度求解公式看起来一样，有区别么？

\item L1：$cost(w)={\frac {1}{2m}}\left\|{Xw-y}\right\|^{2}+\lambda\|w\|_{1}$
，等价于
    $\min\limits_{w}{\frac {1}{2m}}\left\|{Xw-y}\right\|^{2}, s.t. \left\|w\right\|_{1}\le{C}$

\item L2：$cost(w)={\frac {1}{2m}}\left\|{Xw-y}\right\|^{2}+{\frac {\lambda}{2}}\|w\|_{2}^{2}$
，等价于
    $\min\limits_{w}{\frac {1}{2m}}\left\|{Xw-y}\right\|^{2}, s.t. \left\|w\right\|_{2}^{2}\le{C}$

\item 常用分类器的评价指标有：准确率(precision)、召回率(recall)、F值、正确率(accuracy)等
\end{itemize}

\begin{itemize}

\item 考虑ROC曲线图中的四个点。
    \subitem（1）第一个点(0,1)，FPR=0, TPR=1，即FN=0，并且FP=0。
        \subsubitem 特点：正确分类所有的样本。
    \subitem（2）第二个点(1,0)，FPR=1，TPR=0。
        \subsubitem 特点：成功错分了所有的样例。
    \subitem（3）第三个点(0,0)，FPR=TPR=0，即FP=TP=0，
        \subsubitem 特点：分类器预测所有的样本都为负样本。
    \subitem（4）第四个点(1,1)，分类器预测所有的样本都为正样本。
\item 结论：ROC曲线越接近左上角，该分类器的性能越好。
\item 考虑ROC曲线图中的虚线$y=x$上的点。这条对角线上的点表示的是一个采用随机猜测策略的分类器的结果。

\item ROC曲线的画法：对一个特定的测试数据集合，对分类模型输出的概率值设置不同的阈值，从而得到一组（FPR,TPR）点，以此连接这些点即可得到ROC曲线。
\item AUC(Area Under Curve)：ROC曲线下的面积。
\item AUC值等于一个随机选择的正样本的预测值高于一个随机选择的负样本的概率。
\item ROC曲线的优点：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。

\item 在右图中，(a)和(c)为ROC曲线，(b)和(d)为\\
Precision-Recall曲线。(a)和(b)展示的是\\
分类其在原始测试集（正负样本分布平衡）\\
的结果，(c)和(d)是将测试集中负样本的数\\
量增加到原来的10倍后， 分类器的结果。可\\
以明显的看出，ROC曲线基本保持原貌，\\
而Precision-Recall曲线则变化较大。
\end{itemize}

\subsection{LR解决多分类问题}
基本思路：将多分类任务拆若干个二分类任务。学习时分别训练多个分类器，测试时对这多个分类器的预测结果进行集成以获得最终的多分类结果。

一般来说，有以下几种做法。

\subsubsection{一对一(OvO) }
以$C_{i}$与$C_{j}$的数据作为正反例训练一个分类器，共训练${\frac {N(N-1)}{2}}$个分类器
预测时将样本提交给所有分类器，获取${\frac {N(N-1)}{2}}$个结果，最终结果通过投票产生

\subsubsection{一对多(OvR)}
以$C_{i}$数据为正例，其余类别数据为负例，训练$N$个分类器

\subsubsection{其他}
如多对多(MvM)策略的ECOC编码


\section{Softmax Regression}
为LR在多分类上的推广。与LR一样，同属于广义线性模型（Generalized Linear Model）。

\[
P(y=i|x;{\theta})={\frac {e^{{\theta}_{i}^{T}x}}{\sum_{j=1}^{K}{e^{{\theta}_{j}^{T}x}}}}
\]

同样，考虑使得对数似然最大，则系统损失函数为：
\[
\ell(\theta)=-{\frac {1}{m}}\left[\sum\limits_{i=1}^{m}{\sum\limits_{j=1}^{K}{1\{y^{(i)}=j\}\log{\frac{e^{{\theta}_{j}^{T}{x^{(i)}}}}{\sum_{l=1}^{K}{e^{\theta_{l}^{T}x^{(i)}}}}}}}\right]
\]

加入正则项：
\[
\ell(\theta)=-{\frac {1}{m}}\left[\sum\limits_{i=1}^{m}{\sum\limits_{j=1}^{K}{1\{y^{(i)}=j\}\log{\frac{e^{{\theta}_{j}^{T}{x^{(i)}}}}{\sum_{l=1}^{K}{e^{\theta_{l}^{T}x^{(i)}}}}}}}\right]+
    {\frac {\lambda}{2}{\sum\limits_{i=1}^{K}{\sum\limits_{j=0}^{n}{\theta_{ij}^{2}}}}}
\]

考虑一个样本$(x,y)$，有$\ell(x,\hat{y})=-\sum\limits_{j=1}^{K}{1\{y=j\}\ln{\hat{y}_{j}}}$，令$a_{j}={\theta_{j}^{T}x}$，有
\begin{align*}
{\frac {\partial \ell(x,\hat{y})}{a_{j}}}&=\sum\limits_{i=1}^{K}{{\frac {\partial \ell(x,\hat{y})}{\partial \hat{y}_{i}}}{\frac {\partial \hat{y}_{i}}{\partial a_{j}}}}\\
                                         &=-\sum\limits_{i=1}^{K}{
                                                {\frac {1\{y=i\}}{\hat{y}_{i}}}
                                                {\frac {\partial \frac {e^{a_{i}}}{\sum_{l=1}^{K}{e^{a_{l}}}}}{\partial a_{j}}}}\\
                                         &=-\sum\limits_{i=1}^{K}{
                                                {\frac {1\{y=i\}}{\hat{y}_{i}}}
                                                {\frac {
                                                            e^{a_{i}} \cdot 1\{i=j\} \cdot {\left({\sum_{l=1}^{K}{e^{a_{l}}}}\right)}
                                                            -e^{a_{i}} \cdot e^{a_{j}}
                                                        }
                                                       {\left({\sum_{l=1}^{K}{e^{a_{l}}}}\right)^{2}}
                                                    }}\\
                                         &=\sum\limits_{i=1}^{K}{
                                                {\frac {1\{y=i\}}{\hat{y}_{i}}}
                                                {\frac {e^{a_{i}} \cdot e^{a_{j}}}
                                                       {\left({\sum_{l=1}^{K}{e^{a_{l}}}}\right)^{2}}
                                                    }}
                                            -\sum\limits_{i=1}^{K}{
                                                {\frac {1\{y=i\}}{\hat{y}_{i}}}
                                                {\frac {e^{a_{i}} \cdot 1\{i=j\} \cdot {\left({\sum_{l=1}^{K}{e^{a_{l}}}}\right)}}
                                                       {\left({\sum_{l=1}^{K}{e^{a_{l}}}}\right)^{2}}
                                                    }}\\
                                         &=\sum\limits_{i=1}^{K}{{\frac {1\{y=i\}}{\hat{y}_{i}}}{\hat{y}_{i}}{\hat{y}_{j}}}
                                            -\sum\limits_{i=1}^{K}{{\frac {1\{y=i\}}{\hat{y}_{i}}}{\hat{y}_{i}} \cdot 1\{i=j\}}\\
                                         &={\hat{y}_{j}}-\sum\limits_{i=1}^{K}{{1\{y=i\}}} \cdot 1\{i=j\}\\
                                         &={\hat{y}_{j}}-{1\{y=j\}} \\
\end{align*}

对于多分类问题，LR与softmax之间如何选择
\begin{itemize}
\item 如果待分的类别互斥，使用softmax
\item 如果类别有交叉，则使用LR进行投票分类
\item 例如
    \subitem 有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐
    \subitem 有四个类别如下：人声音乐、舞曲、影视原声、流行歌曲
\end{itemize}

\begin{itemize}
\item 实际工程中，LR很少使用连续特征。一般将连续特征离散化成多个取值为0/1的离散特征。
\subitem 0. 离散特征的增加和减少都很容易，易于模型的快速迭代；
\subitem 1. 稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；
\subitem 2. 离散化后的特征对异常数据有很强的鲁棒性；
\subitem 3. 逻辑回归属于广义线性模型，表达能力受限；离散化相当于为模型引入了非线性，提升模型表达能力；
\subitem 4. 离散化后可以进行特征交叉，由$M+N$个变量变为$M*N$个变量，进一步引入非线性，提升表达能力；
\subitem 5. 特征离散化后，模型会更稳定；
\subitem 6. 特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。

\end{itemize}




\begin{itemize}
\item 监督学习：利用一组已知类别的样本调整分类器的参数，\\使其达到所要求性能的过程
\item 一些符号定义：

$x^{(i)}$：指数据集中的第$i$个样本的特征类数据。

$y^{(i)}$：指数据集中的第$i$个样本的目标值。

$\left(x^{(i)},y^{(i)}\right)$：表示一个样本实例。

$\left\{\left(x^{(i)},y^{(i)}\right), i=1,...,N\right\}$：表示一个数据集。
\\例如，对于手写体识别来说，图片的像素表示即为特征$x$，图片表示的数字即为目标值$y$。

\end{itemize}

对于红酒问题，
\begin{itemize}
\item 问题分析：
\\(1) 共有11个特征，可表示为11个变量：$x^{(i)}_1,x^{(i)}_2,...,x^{(i)}_{11}$。
\\(2) 目标只有一个评分，可表示为：$y^{(i)}$
\\(3) 问题可表示为优化问题：$argmin_{w}\sum_{i=1}^{N}(w_0 + w_1*x^{(i)}_1 + w_2*x^{(i)}_2 + w_{11}*x^{(i)}_{11} - y^{(i)})^2$

\item 用向量表示更加简洁：
\\(1) 特征表示为：$x^{(i)}=\left(\begin{array}{ccc}x^{(i)}_0,x^{(i)}_1,...,x^{(i)}_{11}\end{array}\right)^T$,其中$x^{(i)}_0=1$
\\(2) 权重系数表示为：$w=\left(\begin{array}{ccc}w_0,w_1,...,w_{11}\end{array}\right)^T$
\\(3) 问题表示为：$argmin_{w} \sum_{i=1}^{N}(w^Tx^{(i)}-y^{(i)})^2$

\end{itemize}

\begin{equation}
  s_{kk'}=
  \left(
  \begin{array}{ccc}
          h_{1k} &
          \cdots &
          h_{nk}
  \end{array}
  \right)
  \left(
  \begin{array}{ccc}
          \bar{q}_{11} & \cdots & \bar{q}_{12}\\
          \vdots & \ddots & \vdots\\
          \bar{q}_{n1} & \cdots & \bar{q}_{n2}
  \end{array}
  \right)
  \left(
  \begin{array}{c}
          h_{1k'} \\
          \vdots \\
          h_{nk'}
 \end{array}
 \right)
\end{equation}


%\\$x=\begin{matrix} 0 & 1 \end{matrix}$

\subsubsection{Linear Regression}
\begin{itemize}

\item 给定一份数据集$\left\{x_0^{(i)},x_1^{(i)},...,x_m^{(i)},y^{(i)}\right\}_{i=0}^{N-1}$，线性回归假设目标值$y^{(i)}$与特征$x^{(i)}$之间为线性关系，即：$$y^{(i)}=w_0x_0^{(i)}+w_1x_1^{(i)}+...+w_mx_m^{(i)}$$

\item 现实世界不存在完美线性相关的关系，总会有各\\
种各样的偏差存在。由大数定理，可假设真实值\\
总在理论值附近波动，误差符合高斯分布, 即：\\
$y^{(i)}=w_0x_0^{(i)}+w_1x_1^{(i)}+...+w_mx_m^{(i)}+\varepsilon^{(i)}$\\
其中，$\varepsilon^{(i)}\sim{\mathcal{N}}(0, \sigma^{2})$
%其中，$\varepsilon\sim{\mathcal{N}}(\mu, \sigma^{2})$

\item 假设训练集中一共有$N$个样本：

$X=\left(
\begin{array}{c}
        {(x^{(0)})}^T \\
        {(x^{(1)})}^T \\
        \vdots \\
        {(x^{(N-1)})}^T \\
\end{array}
\right)=\left(
\begin{array}{ccc}
        x_0^{(0)} & \cdots & x_m^{(0)} \\
        x_0^{(1)} & \cdots & x_m^{(1)} \\
        \vdots & \ddots & \vdots\\
        x_0^{(N-1)} & \cdots & x_m^{(N-1)}
\end{array}
\right)$
$w=\left(
\begin{array}{c}
        w^{(0)} \\
        w^{(1)} \\
        \vdots \\
        w^{(m)}
\end{array}
\right)$
$y=\left(
\begin{array}{c}
        y^{(0)} \\
        y^{(1)} \\
        \vdots \\
        y^{(N-1)}
\end{array}
\right)$

\item 线性回归的目标就是最小化预估值与真实值的差距，也即所求$w$满足：$$argmin \left\|{Xw-y}\right\|^{2}$$
\item 代数解：$w=(X^{T}X)^{-1}X^{T}y$
\end{itemize}


\begin{itemize}
\item 代数解非常优美：\\
(1) 当$X^{T}X$为满秩矩阵或正定矩阵时，上式有唯一解。\\
(2) 现实任务中往往不是满秩矩阵，即$X^{T}X$不可逆，原因有很多，例如：
    \begin{itemize}
    \item 存在冗余特征，例如特征之间相关
    \item 训练样本少，如特征数甚至超过样本数
    \end{itemize}
此时$w$有多个可行解，需要选择最佳$w$。 \\
(3) 此代数解运算复杂度高，当$n>10000$时开销过大。\\

\end{itemize}

\subparagraph{梯度下降}
介绍梯度下降的原理。
\subsection{理论}

\begin{itemize}
\item 想法：人类在学习的时候，都是渐进式学习，不断从错误中纠正自己的认知，从而越来越优秀。
\item 导数定义：$ {\frac {dy}{dx}}={\frac {df}{dx}}(x)={\frac {d}{dx}}f(x)=f'(x)=\lim_{{\Delta x}\to 0}{\frac {f(x+{\Delta x})-f(x)}{\Delta x}} $\\
有：$f(x+{\Delta x})-f(x)=f'(x){\Delta x}$
\\(1) 如果$f'(x)>0$:
\subitem 当${\Delta x}>0$时，$f(x+{\Delta x})-f(x)=f'(x){\Delta x}>0$;
\subitem 当${\Delta x}<0$时，$f(x+{\Delta x})-f(x)=f'(x){\Delta x}<0$
\\(2) 如果$f'(x)<0$：
\subitem 当${\Delta x}>0$时，$f(x+{\Delta x})-f(x)=f'(x){\Delta x}<0$;
\subitem 当${\Delta x}<0$时，$f(x+{\Delta x})-f(x)=f'(x){\Delta x}>0$
\item 结论：如果使$x$变化的方向与$f'(x)$一致，将会使得$f(x)$增加。
\end{itemize}

\begin{itemize}
\item 梯度：$\nabla f=\left({\frac {\partial f}{\partial x_{1}}},\dots ,{\frac {\partial f}{\partial x_{n}}}\right)$，其中$\left(\nabla f\right)_{i}={\frac {\partial f}{\partial x_{i}}}$
\item 梯度下降算法(Gradient Descent)：沿梯度下降的方向求解极小值。
\item 算法过程：
\\(1) 初始化参数为任意值。例如线性回归中的$w$。
\\(2) 求解梯度。例如线性回归中，求解 $\nabla\left(\left\|{Xw-y}\right\|^{2}\right)$。
\\(3) 更新参数。例如线性回归中，更新参数$w$，\\使得$w=w-\alpha\nabla\left(\left\|{Xw-y}\right\|^{2}\right)$，$\alpha$称为学习率。
\\(4) 若达到指定迭代次数或者收敛条件，训练结束。\\否则，继续执行步骤(2)。
\end{itemize}

\begin{itemize}
\item 实际应用中，对梯度下降算法有很多变形或改进。
\item 随机梯度下降（stochastic gradient descent）：每遇到
\\一个或者多个但不是整个样本集，就计算梯度，更新参数。
\item 算法过程：
\\(1) 初始化参数为任意值。例如线性回归中的$w$。
\\(2) 对样本集中的每个样本，做如下操作直接完成所有样本\\的遍历：
\subitem(2.1) 求解梯度。例如线性回归中，求解 $\nabla\left(\left\|{Xw-y}\right\|^{2}\right)$。
\subitem(2.2) 更新参数。例如线性回归中，更新参数$w$，使得$w=w-\alpha\nabla\left(\left\|{Xw-y}\right\|^{2}\right)$。
\\(3) 若达到指定迭代次数或者收敛条件，训练结束。否则，继续执行步骤(2)。
\end{itemize}

\begin{itemize}
\item 一个完整的有监督学习的开发流程：
\\(1) 获取数据，对数据做一些清洗、转换等操作。
\\(2) 将数据样本拆分成训练集、验证集和测试集。训练集用来训练模型，验证集用来评估模型效果和调参，测试集则用来评估最终的模型效果。
\\(3) 开发模型或直接使用开发好的模型工具，在训练集上进行训练。
\\(4) 获取训练好的模型，使用验证集评估其效果。如果没有达到预期，需要进一步对模型调参、获取新的特征等操作，直到满足训练效果为止。
\\(5) 使用训练好的模型，在测试集上评估其最终效果。

\item 对于葡萄酒质量预估任务来说，主要有以下过程（只使用白酒的数据）：
\\(1) 获取数据集，对数据集做一些预处理操作。
\\(2) 将处理好的数据集分为训练集、验证集和测试集，比例为：0.7:0.2:0.1。
\\(3) 开发线性回归模型。
\\(4) 在训练集上训练线性模型，在验证集上验证模型效果。没有达到预期，需要调参，直到满足训练效果为止。
\\(5) 在测试集中获取最终效果。

\end{itemize}

$x'={\frac {x - x_{min}}{x_{max} - x_{min}}}$

\begin{itemize}
\item 正则项：为有效控制模型参数的复杂度，加入参数复杂度的惩罚项，以使得模型选择更加简单的参数。
\item L1正则：$cost(w)={\frac {1}{2N}}\left\|{Xw-y}\right\|^{2}+\lambda\|w\|_{1}$
\item L2正则：$cost(w)={\frac {1}{2N}}\left\|{Xw-y}\right\|^{2}+{\frac {\lambda}{2}}\|w\|_{2}^{2}$
\\

加入正则项后，梯度：
\item L1正则：$w=w-\alpha (w^{T}x^{(i)}-y^{(i)})x^{(i)} - \alpha\lambda w$
\item L2正则：$w=w-\alpha (w^{T}x^{(i)}-y^{(i)})x^{(i)} - \alpha\lambda sign(w)$
\end{itemize}

\begin{itemize}
\item 优化目标：$cost(w)={\frac {1}{2N}}\left\|{Xw-y}\right\|^{2}$
\item 对于单个样本来说：$cost(w)={\frac {1}{2}}\left({w^{T}x^{(i)}-y^{(i)}}\right)^{2}$
\item 单个样本的梯度为：$\nabla cost(w)=(w^{T}x^{(i)}-y^{(i)})x^{(i)}$
\item 梯度更新：$w=w-\alpha (w^{T}x^{(i)}-y^{(i)})x^{(i)}$
\item 样本特征的取值情况如右图所示
\item 特征归一化： $x'={\frac {x - x_{min}}{x_{max} - x_{min}}}$

\end{itemize}

\subsection{交叉验证{\color{red} TODO}}

交叉验证（Cross Validation），有的时候也称作循环估计（Rotation Estimation），是一种统计学上将数据样本切割成较小子集的实用方法，该理论是由Seymour Geisser提出的。

在模式识别（Pattern Recognition）和机器学习（Machine Learning）的相关研究中，经常会将整个数据集合分成两个部分，分别是训练集合和测试集合。假设X是集合全体，A是全集X的非空真子集，那么非空集合X\textbackslash{A}则是集合A在全集X中的补集。于是可以先在A上面做训练和分析，而集合X\textbackslash{A}则用来做测试和验证。一开始的集合A被称作训练集，而它的补集X\textbackslash{A}被称作验证集或者测试集。这里有一个重要的观点就是：只有训练集才可以使用在模型的训练之中，而测试集必须在模型训练完成之后才被用来评估模型的误差。

\subsubsection{HoldOut检验（Hold-Out Method）}
这个方法是将原始的数据集合X随机分成两个集合A和X\textbackslash{A}，其中A作为训练集，X\textbackslash{A}作为测试集。先使用训练集训练模型，然后利用测试集验证模型的效果，记录最后的分类准确率作为Hold-Out下该模型的性能指标。比方说，处理时间序列模型是否准确的时候，把整个数据集合分成前后两部分，前部分占比70\%，后部分占比30\%。前部分来进行时间序列模型的训练，后部分用来测试改时间序列的准确性。其准确性可以用MAE，MAPE之类的统计指标来衡量。综上所述，该方法的好处就是处理起来简单，只需要把原始数据分成两个部分即可。但是从严格意义上来说，Hold-Out检验并不算是交叉检验（Cross Validation），因为该方法没有达到交叉检验的思想，而且最后验证准确性的高低和原始数组的分类有很大的关系，所以该方法得到的结果在某些场景中并不具备特别大的说服力。在Hold-Out检验不够有说服力的情形下，有人提出了交叉验证这一个重要思想。

\subsubsection{交叉检验的常见形式}
假设有一个未知模型有一个或者多个未知的参数，并且有一个训练集。操作的过程就是对该模型的参数进行调整，使得该模型能够最大的反映训练集的特征。如果模型因为训练集过小或者参数不合适而产生过度拟合的情况，测试集的测试效果就可以得到验证。交叉验证是一种能够预测模型拟合性能的有效方法。

\subsubsection{彻底的交叉验证（Exhaustive Cross Validation）}
彻底的交叉验证方法指的是遍历全集X的所有非空真子集A。换句话说也就是把A当作训练集，X\textbackslash{A}是测试集。如果X中有n个元素，那么非空真子集A的选择方法则是$2^{n}-2$，这个方法的时间复杂度是指数级别的。

\begin{itemize}
\item 留P验证（Leave-p-out Cross Validation)
留p验证（LpO CV）指的是使用全集X中的p个元素作为测试集，然后剩下的n-p个元素作为训练集。根据数学上的定理可以得到，p个元素的选择方法有n!/((n-p)!p!)个，其中n!表示n的阶乘。在这个意义下，留p验证的时间复杂度也是非常高的。当p=1的时候，留1验证（Leave-one-out Cross Validation）的复杂度恰好是n。

\item 不彻底的交叉验证（Non-exhaustive Cross Validation）
不彻底的交叉验证不需要考虑全集X的所有划分情况，这种方法是留p验证的一个近似验证算法。

\item k-fold交叉验证（K-fold Cross Validation）
在k-fold交叉验证中，全集X被随机的划分成k个同等大小的集合A1,...,Ak，并且|A1|=...=|Ak|。这里的|Ai|指的是集合Ai的元素个数，也就是集合的势。这个时候需要遍历i从1到k，把X\textbackslash{Ai}当作训练集合，Ai当作测试集合。根据模型的测试统计，可以得到Ai集合中测试错误的结果数量ni。如果全集X的势是n的话，可以得到该模型的错误率是E=(ni求和)/n.
为了提高模型的精确度，可以将k-fold交叉验证的上述步骤重复t次，每一次都是随机划分全集X。在t次测试中，会得到t个模型的错误率E1,...,Et。令e=(Ei求和)/t。这样该模型的错误率就是e。

注释：
一般来说，k=10的情况使用得最多。
当k=2的时候，也就是最简单的k-fold交叉验证，2-fold交叉验证。这个时候X是A1和A2的并集，首先A1当训练集并且A2当测试集，然后A2当训练集并且A1当测试集。2-fold交叉验证的好处就是训练集和测试集的势都非常大，每个数据要么在训练集中，要么在测试集中。
当k=n的时候，也就是n-fold交叉验证。这个时候就是上面所说的留一验证（Leave-one-out Cross Validation）。
\end{itemize}
综上所述，交叉验证（Cross Validation）的好处是可以从有限的数据中获得尽可能多的有效信息，从而可以从多个角度去学习样本，避免陷入局部的极值。在这个过程中，无论是训练样本还是测试样本都得到了尽可能多的学习。

一般模型的选择过程：
在了解了交叉验证的方法之后，可以来介绍一般模型的选择过程。通过采用不同的输入训练样本，来决定机器学习算法中包含的各个参数值，称作模型选择。下面伪代码表示了模型选择的一般流程。在这个算法中，最重要的就是第三个步骤中的误差评价。 
（1）准备候选的q个模型:M1,...,Mq。 
（2）对每个模型M1,...,Mq求解它的学习结果。 
（3）对每个学习结果的误差e1,...,eq进行计算。这里可以使用上面所说的k-fold交叉验证方法。 
（4）选择误差e1,...,eq最小的模型作为最终的模型。









交叉验证是一种用来评价一个统计分析的结果是否可以推广到一个独立的数据集上的技术。主要用于预测，即，想要估计一个预测模型的实际应用中的准确度。它是一种统计学上将数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析， 而其它子集则用来做后续对此分析的确认及验证。 

交叉验证的理论是由Seymour Geisser所开始的。 它对于防范testing hypotheses suggested by the data是非常重要的，特别是当后续的样本是危险、成本过高或不可能（uncomfortable science）去搜集。

一个交叉验证将样本数据集分成两个互补的子集，一个子集用于训练（分类器或模型）称为训练集（training set）；另一个子集用于验证（分类器或模型的）分析的有效性称为测试集（testing set）。利用测试集来测试训练得到的分类器或模型，以此作为分类器或模型的性能指标。

得到高度预测精确度和低的预测误差，是研究的期望。为了减少交叉验证结果的可变性，对一个样本数据集进行多次不同的划分，得到不同的互补子集，进行多次交叉验证。取多次验证的平均值作为验证结果。

在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。

\subsubsection{目的}
用交叉验证的目的是为了得到可靠稳定的模型。在建立PCR 或PLS 模型时，一个很重要的因素是取多少个主成分的问题？用cross validation 校验每个主成分下的PRESS值，选择PRESS值小的主成分数。或PRESS值不在变小时的主成分数

交叉验证的目的：假设分类器或模型有一个或多个未知的参数，并且设这个训练器（模型）与已有样本数据集（训练数据集）匹配。训练的过程是指优化模型的参数，以使得分类器或模型能够尽可能的与训练数据集匹配。我们在同一数据集总体中，取一个独立的测试数据集。
\subsubsection{常见类型的交叉验证}
\begin{itemize}
\item 重复随机子抽样验证。
    \subitem 做法：将数据集随机的划分为训练集和测试集。对每一个划分，用训练集训练分类器或模型，用测试集评估预测的精确度。进行多次划分，用均值来表示效能。
    \subitem 优点：与k倍交叉验证相比，这种方法的与k无关。
    \subitem 缺点：有些数据可能从未做过训练或测试数据；而有些数据不止一次选为训练或测试数据。
\item 2、K倍交叉验证（K>=2）。
    \subitem 做法：将样本数据集随机划分为K个子集（一般是均分），将一个子集数据作为测试集，其余的K-1组子集作为训练集；将K个子集轮流作为测试集，重复上述过程，这样得到了K个分类器或模型，并利用测试集得到了K个分类器或模型的分类准确率。用K个分类准确率的平均值作为分类器或模型的性能指标。10-倍交叉证实是比较常用的。
    \subitem 优点：每一个样本数据都即被用作训练数据，也被用作测试数据。避免的过度学习和欠学习状态的发生，得到的结果比较具有说服力。
\item 3、留一法交叉验证。
    \subitem 做法：假设样本数据集中有N个样本数据。将每个样本单独作为测试集，其余N-1个样本作为训练集，这样得到了N个分类器或模型，用这N个分类器或模型的分类准确率的平均数作为此分类器的性能指标。
    \subitem 优点：每一个分类器或模型都是用几乎所有的样本来训练模型，最接近样本，这样评估所得的结果比较可靠。实验没有随机因素，整个过程是可重复的。
    \subitem 缺点：计算成本高，当N非常大时，计算耗时。
\end{itemize}

\subsubsection{训练集和测试集的选取}
\begin{itemize}
\item 1、训练集中样本数量要足够多，一般至少大于总样本数的50%。
\item 2、训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。（随机取样，可重复性差）
\end{itemize}

\ifx\mlbook\undefined
    \end{document}
\fi
