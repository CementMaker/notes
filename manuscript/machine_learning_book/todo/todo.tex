\ifx\mlbook\undefined
    \documentclass[10pt,a4paper]{ctexbook}
    \providecommand{\pathroot}{../..}

    \usepackage[CJKbookmarks,colorlinks,linkcolor=red]{hyperref}
    \usepackage{geometry}
    \usepackage{amsmath}
    \usepackage{minted}

    \geometry{left=3.0cm,right=3.0cm,top=2.5cm,bottom=2.5cm}
    \setmainfont{SimSun}
    \XeTeXlinebreaklocale "zh"
    \XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

    \begin{document}
    \setlength{\baselineskip}{20pt}
    \title{待整理材料}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{Nov 7, 2017}
    %\maketitle
    \tableofcontents
\fi

\chapter{待整理}
\textbf{Basis(基础)}
\begin{itemize}
\item SSE(Sum of Squared Error, 平方误差和)
\item SAE(Sum of Absolute Error, 绝对误差和)
\item SRE(Sum of Relative Error, 相对误差和)
\item MSE(Mean Squared Error, 均方误差)
\item RMSE(Root Mean Squared Error, 均方根误差)
\item RRSE(Root Relative Squared Error, 相对平方根误差)
\item MAE(Mean Absolute Error, 平均绝对误差)
\item RAE(Root Absolute Error, 平均绝对误差平方根)
\item MRSE(Mean Relative Square Error, 相对平均误差)
\item RRSE(Root Relative Squared Error, 相对平方根误差)
\item Expectation(期望)\&Variance(方差)
\item Standard Deviation(标准差，也称Root Mean Squared Error, 均方根误差)
\item CP(Conditional Probability, 条件概率)
\item JP(Joint Probability, 联合概率)
\item MP(Marginal Probability, 边缘概率)
\item Bayesian Formula(贝叶斯公式)
\item CC(Correlation Coefficient, 相关系数)
\item Quantile (分位数)
\item Covariance(协方差矩阵)
\item GD(Gradient Descent, 梯度下降)
\item SGD(Stochastic Gradient Descent, 随机梯度下降)
\item LMS(Least Mean Squared, 最小均方)
\item LSM(Least Square Methods, 最小二乘法)
\item NE(Normal Equation, 正规方程)
\item MLE(Maximum Likelihood Estimation, 极大似然估计)
\item QP(Quadratic Programming, 二次规划)
\item L1 /L2 Regularization(L1/L2正则, 以及更多的, 现在比较火的L2.5正则等)
\item Eigenvalue(特征值)
\item Eigenvector(特征向量)
\end{itemize}

\textbf{Common Distribution(常见分布)：}
\textbf{Discrete Distribution(离散型分布)：}
\begin{itemize}
\item Bernoulli Distribution/Binomial Distribution(贝努利分布/二项分布)
\item Negative Binomial Distribution(负二项分布)
\item Multinomial Distribution(多项分布)
\item Geometric Distribution(几何分布)
\item Hypergeometric Distribution(超几何分布)
\item Poisson Distribution (泊松分布)
\end{itemize}

\textbf{Continuous Distribution (连续型分布)：}
\begin{itemize}
\item Uniform Distribution(均匀分布)
\item Normal Distribution/Gaussian Distribution(正态分布/高斯分布)
\item Exponential Distribution(指数分布)
\item Lognormal Distribution(对数正态分布)
\item Gamma Distribution(Gamma分布)
\item Beta Distribution(Beta分布)
\item Dirichlet Distribution(狄利克雷分布)
\item Rayleigh Distribution(瑞利分布)
\item Cauchy Distribution(柯西分布)
\item Weibull Distribution (韦伯分布)
\end{itemize}

\textbf{Three Sampling Distribution(三大抽样分布)：}
\begin{itemize}
\item Chi-square Distribution(卡方分布)
\item t-distribution(t-分布)
\item F-distribution(F-分布)
\end{itemize}

\textbf{Data Pre-processing(数据预处理)：}
\begin{itemize}
\item Missing Value Imputation(缺失值填充)
\item Discretization(离散化)
\item Mapping(映射)
\item Normalization(归一化/标准化)
\end{itemize}

\textbf{Sampling(采样)：}
\begin{itemize}
\item Simple Random Sampling(简单随机采样)
\item Offline Sampling(离线等可能K采样)
\item Online Sampling(在线等可能K采样)
\item Ratio-based Sampling(等比例随机采样)
\item Acceptance-rejection Sampling(接受-拒绝采样)
\item Importance Sampling(重要性采样)
\item MCMC(Markov Chain MonteCarlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting\& Gibbs)
\end{itemize}

\textbf{Clustering(聚类)：}
\begin{itemize}
\item K-MeansK-Mediods
\item 二分K-Means
\item FK-Means
\item Canopy
\item Spectral-KMeans(谱聚类)
\item GMM-EM(混合高斯模型-期望最大化算法解决)
\item K-Pototypes
\item CLARANS(基于划分)
\item BIRCH(基于层次)
\item CURE(基于层次)
\item STING(基于网格)
\item CLIQUE(基于密度和基于网格)
\item 2014年Science上的密度聚类算法等
\end{itemize}

\textbf{Clustering Effectiveness Evaluation(聚类效果评估)：}
\begin{itemize}
\item Purity(纯度)
\item RI(Rand Index, 芮氏指标)
\item ARI(Adjusted Rand Index, 调整的芮氏指标)
\item NMI(Normalized Mutual Information, 规范化互信息)
\item F-meaure(F测量)
\end{itemize}

\textbf{Classification\&Regression(分类\&回归)：}
\begin{itemize}
\item LR(Linear Regression, 线性回归)
\item LR(Logistic Regression, 逻辑回归)
\item SR(Softmax Regression, 多分类逻辑回归)
\item GLM(Generalized Linear Model, 广义线性模型)
\item RR(Ridge Regression, 岭回归/L2正则最小二乘回归)，LASSO(Least Absolute Shrinkage and Selectionator Operator , L1正则最小二乘回归)
\item DT(Decision Tree决策树)
\item RF(Random Forest, 随机森林)
\item GBDT(Gradient Boosting Decision Tree, 梯度下降决策树)
\item CART(Classification And Regression Tree 分类回归树)
\item KNN(K-Nearest Neighbor, K近邻)
\item SVM(Support Vector Machine, 支持向量机, 包括SVC(分类)\&SVR(回归))
\item CBA(Classification based on Association Rule, 基于关联规则的分类)
\item KF(Kernel Function, 核函数) 
    \subitem Polynomial Kernel Function(多项式核函数)
    \subitem Guassian Kernel Function(高斯核函数)
    \subitem Radial Basis Function(RBF径向基函数)
    \subitem String Kernel Function 字符串核函数
\item NB(Naive Bayesian,朴素贝叶斯)
\item BN(Bayesian Network/Bayesian Belief Network/Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)
\item LDA(Linear Discriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别)
\item EL(Ensemble Learning, 集成学习) 
    \subitem Boosting
    \subitem Bagging
    \subitem Stacking
    \subitem AdaBoost(Adaptive Boosting 自适应增强)
\item MEM(Maximum Entropy Model, 最大熵模型)
\end{itemize}

\textbf{Classification EffectivenessEvaluation(分类效果评估)：}
\begin{itemize}
\item Confusion Matrix(混淆矩阵)
\item Precision(精确度)
\item Recall(召回率)
\item Accuracy(准确率)
\item F-score(F得分)
\item ROC Curve(ROC曲线)
\item AUC(AUC面积)
\item Lift Curve(Lift曲线)
\item KS Curve(KS曲线)
\end{itemize}

\textbf{PGM(Probabilistic Graphical Models, 概率图模型)：}
\begin{itemize}
\item BN(BayesianNetwork/Bayesian Belief Network/ Belief Network , 贝叶斯网络/贝叶斯信度网络/信念网络)
\item MC(Markov Chain, 马尔科夫链)
\item MEM(Maximum Entropy Model, 最大熵模型)
\item HMM(Hidden Markov Model, 马尔科夫模型)
\item MEMM(Maximum Entropy Markov Model, 最大熵马尔科夫模型)
\item CRF(Conditional Random Field,条件随机场)
\item MRF(Markov Random Field, 马尔科夫随机场)
\item Viterbi(维特比算法)
\end{itemize}


\textbf{NN(Neural Network, 神经网络)}
\begin{itemize}
\item ANN(Artificial Neural Network, 人工神经网络)
\item SNN(Static Neural Network, 静态神经网络)
\item BP(Error Back Propagation, 误差反向传播)
\item HN(Hopfield Network)
\item DNN(Dynamic Neural Network, 动态神经网络)
\item RNN(Recurrent Neural Network, 循环神经网络)
\item SRN(Simple Recurrent Network, 简单的循环神经网络)
\item ESN(Echo State Network, 回声状态网络)
\item LSTM(Long Short Term Memory, 长短记忆神经网络)
\item CW-RNN（Clockwork-Recurrent Neural Network, 时钟驱动循环神经网络, 2014ICML）等
\end{itemize}

\textbf{Deep Learning(深度学习)：}
\begin{itemize}
\item Auto-encoder(自动编码器)
\item SAE(Stacked Auto-encoders堆叠自动编码器) 
    \subitem Sparse Auto-encoders(稀疏自动编码器)
    \subitem Denoising Auto-encoders(去噪自动编码器)
    \subitem Contractive Auto-encoders(收缩自动编码器)
\item RBM(Restricted Boltzmann Machine, 受限玻尔兹曼机)
\item DBN(Deep Belief Network, 深度信念网络)
\item CNN(Convolutional Neural Network, 卷积神经网络)
\item Word2Vec(词向量学习模型)
\end{itemize}

\textbf{Dimensionality Reduction(降维)：}
\begin{itemize}
\item LDA(Linear Discriminant Analysis/Fisher Linear Discriminant, 线性判别分析/Fish线性判别)
\item PCA(Principal Component Analysis, 主成分分析)
\item ICA(Independent Component Analysis, 独立成分分析)
\item SVD(Singular Value Decomposition 奇异值分解)
\item FA(Factor Analysis 因子分析法)
\end{itemize}

\textbf{Text Mining(文本挖掘)：}
\begin{itemize}
\item VSM(Vector Space Model, 向量空间模型)
\item Word2Vec(词向量学习模型)
\item TF(Term Frequency, 词频)
\item TF-IDF(TermFrequency-Inverse Document Frequency, 词频-逆向文档频率)
\item MI(Mutual Information, 互信息)
\item ECE(Expected Cross Entropy, 期望交叉熵)
\item QEMI(二次信息熵)
\item IG(Information Gain, 信息增益)
\item IGR(Information Gain Ratio, 信息增益率)
\item Gini(基尼系数)
\item x2 Statistic(x2统计量)
\item TEW(Text Evidence Weight, 文本证据权)
\item OR(Odds Ratio, 优势率)
\item N-Gram Model
\item LSA(Latent Semantic Analysis, 潜在语义分析)
\item PLSA(Probabilistic Latent Semantic Analysis, 基于概率的潜在语义分析)
\item LDA(Latent Dirichlet Allocation, 潜在狄利克雷模型)
\item SLM(Statistical Language Model, 统计语言模型)
\item NPLM(Neural Probabilistic Language Model, 神经概率语言模型)
\item CBOW(Continuous Bag of Words Model, 连续词袋模型)
\item Skip-gram(Skip-gram Model)
\end{itemize}

\textbf{Association Mining(关联挖掘)：}
\begin{itemize}
\item Apriori算法
\item FP-growth(Frequency Pattern Tree Growth, 频繁模式树生长算法)
\item MSApriori(Multi Support-based Apriori, 基于多支持度的Apriori算法)
\item GSpan(Graph-based Substructure Pattern Mining, 频繁子图挖掘)
\end{itemize}

\textbf{Sequential Patterns Analysis(序列模式分析)}
\begin{itemize}
\item AprioriAll
\item Spade
\item GSP(Generalized Sequential Patterns, 广义序列模式)
\item PrefixSpan
\end{itemize}

\textbf{Forecast(预测)}
\begin{itemize}
\item LR(Linear Regression, 线性回归)
\item SVR(Support Vector Regression, 支持向量机回归)
\item ARIMA(Autoregressive Integrated Moving Average Model, 自回归积分滑动平均模型)
\item GM(Gray Model, 灰色模型)
\item BPNN(BP Neural Network, 反向传播神经网络)
\item SRN(Simple Recurrent Network, 简单循环神经网络)
\item LSTM(Long Short Term Memory, 长短记忆神经网络)
\item CW-RNN(Clockwork Recurrent Neural Network, 时钟驱动循环神经网络)
\end{itemize}

\textbf{Linked Analysis(链接分析)}
\begin{itemize}
\item HITS(Hyperlink-Induced Topic Search, 基于超链接的主题检索算法)
\item PageRank(网页排名)
\end{itemize}

\textbf{Recommendation Engine(推荐引擎)：}
\begin{itemize}
\item SVD
\item Slope One
\item DBR(Demographic-based Recommendation, 基于人口统计学的推荐)
\item CBR(Context-based Recommendation, 基于内容的推荐)
\item CF(Collaborative Filtering, 协同过滤)
\item UCF(User-based Collaborative Filtering Recommendation, 基于用户的协同过滤推荐)
\item ICF(Item-based Collaborative Filtering Recommendation, 基于项目的协同过滤推荐)
\end{itemize}

\textbf{Similarity Measure\&Distance Measure(相似性与距离度量)：}
\begin{itemize}
\item EuclideanDistance(欧式距离)
\item Chebyshev Distance(切比雪夫距离)
\item Minkowski Distance(闵可夫斯基距离)
\item Standardized EuclideanDistance(标准化欧氏距离)
\item Mahalanobis Distance(马氏距离)
\item Cos(Cosine, 余弦)
\item Hamming Distance/Edit Distance(汉明距离/编辑距离)
\item Jaccard Distance(杰卡德距离)
\item Correlation Coefficient Distance(相关系数距离)
\item Information Entropy(信息熵)
\item KL(Kullback-Leibler Divergence, KL散度/Relative Entropy, 相对熵)
\end{itemize}

\textbf{Optimization(最优化)：}
\textbf{Non-constrained Optimization(无约束优化)：}
\begin{itemize}
\item Cyclic Variable Methods(变量轮换法)
\item Variable Simplex Methods(可变单纯形法)
\item Newton Methods(牛顿法)
\item Quasi-Newton Methods(拟牛顿法)
\item Conjugate Gradient Methods(共轭梯度法)。
\end{itemize}

\textbf{Constrained Optimization(有约束优化)：}
\begin{itemize}
\item Approximation Programming Methods(近似规划法)
\item Penalty Function Methods(罚函数法)
\item Multiplier Methods(乘子法)。
\item Heuristic Algorithm(启发式算法)
\item SA(Simulated Annealing, 模拟退火算法)
\item GA(Genetic Algorithm, 遗传算法)
\item ACO(Ant Colony Optimization, 蚁群算法)
\end{itemize}

\textbf{Feature Selection(特征选择)：}
\begin{itemize}
\item Mutual Information(互信息)
\item Document Frequence(文档频率)
\item Information Gain(信息增益)
\item Chi-squared Test(卡方检验)
\item Gini(基尼系数)
\end{itemize}

\textbf{Outlier Detection(异常点检测)：}
\begin{itemize}
\item Statistic-based(基于统计)
\item Density-based(基于密度)
\item Clustering-based(基于聚类)。
\end{itemize}

\textbf{Learning to Rank(基于学习的排序)：}
\begin{itemize}
\item Pointwise 
    \subitem McRank
\item Pairwise 
    \subitem RankingSVM
    \subitem RankNet
    \subitem Frank
    \subitem RankBoost
\item Listwise 
    \subitem AdaRank
    \subitem SoftRank
    \subitem LamdaMART
\end{itemize}

\textbf{Tool(工具)：}
\begin{itemize}
\item MPI
\item Hadoop生态圈
\item Spark
\item IGraph
\item BSP
\item Weka
\item Mahout
\item Scikit-learn
\item PyBrain
\item Theano 
\end{itemize}

\ifx\mlbook\undefined
    \end{document}
\fi
