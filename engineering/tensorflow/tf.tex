\ifx\engineeringnotes\undefined
    \providecommand{\notesroot}{../..}
    \providecommand{\linuxroot}{.}

    \title{TensorFlow}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{\today\footnote{文档编写开始于2018年5月23日}}

    \input{\notesroot/head}
\else
    \providecommand{\linuxroot}{\engineeringroot/tensorflow}
\fi

\chapter{TensorFlow}
\section{TensorFlow简介}
TensorFlow是谷歌基于DistBelief进行研发的第二代人工智能学习系统，其命名来源于本身的运行原理。Tensor（张量）意味着$N$维数组，Flow（流）意味着基于数据流图的计算，TensorFlow为张量从流图的一端流动到另一端计算过程。TensorFlow是将复杂的数据结构传输至人工智能神经网中进行分析和处理过程的系统。

TensorFlow可被用于语音识别或图像识别等多项机器深度学习领域，对2011年开发的深度学习基础架构DistBelief进行了各方面的改进，它可在小到一部智能手机、大到数千台数据中心服务器的各种设备上运行。TensorFlow完全开源，任何人都可以用。

TensorFlow 表达了高层次的机器学习计算，大幅简化了第一代系统，并且具备更好的灵活性和可延展性。TensorFlow一大亮点是支持异构设备分布式计算，它能够在各个平台上自动运行模型，从手机、单个CPU / GPU到成百上千GPU卡组成的分布式系统。支持CNN、RNN和LSTM算法，这都是目前在Image，Speech和NLP最流行的深度神经网络模型。

这一次的Google开源深度学习系统TensorFlow在很多地方可以应用，如语音识别，自然语言理解，计算机视觉，广告等等。但是，基于以上论点，我们也不能过分夸大TensorFlow这种通用深度学习框架在一个工业界机器学习系统里的作用。在一个完整的工业界语音识别系统里， 除了深度学习算法外，还有很多工作是专业领域相关的算法，以及海量数据收集和工程系统架构的搭建。

不过总的来说，这次谷歌的开源很有意义，尤其是对于中国的很多创业公司来说，他们大都没有能力理解并开发一个与国际同步的深度学习系统，所以TensorFlow会大大降低深度学习在各个行业中的应用难度。

\section{TensorFlow环境搭建}

\section{TensorFlow计算模型--计算图}

\section{TensorFlow代码片段}
\subsection{自定义损失函数}
在预测商品销量时，如果预测多了（预测值比真实销量大），商家损失的是生产商品的成本；而如果预测少了（预测值比真实销量小），损失的则是商品的利润。因为一般商品的成本和商品的利润不会严格相等。比如如果一个商品的成本是1元，但是利润是10元，那么少预测一个就少挣10元；而多预测一个才少挣1元。如果神经网络模型最小化的是均方误差，那么很有可能此模型就无法最大化预期的利润。为了最大化预期利润，需要将损失函数和利润直接联系起来。注意损失函数定义的是损失，所以要将利润最大化，定义的损失函数应该刻画成本或者代价。下面的公式给出了一个当预测多于真实值和预测少于真实值时有不同损失系数的损失函数：
\[
Loss(y,y')=\sum\limits_{i=1}^{n}{f(y_{i},y'_{i})}, \quad f(x,y)=\left\{
\begin{aligned}
    a(x-y), \quad x > y \\
    b(y-x), \quad x \leq y
\end{aligned}
\right.
\]

$y_{i}$为一个batch中第$i$个数据的正确答案，$y'_{i}$为神经网络得到的预测值，$a$和$b$是常量。比如在上面介绍的销量预测问题中，$a$就等于10（正确答案多于预测答案的代价），而$b$等于1（正确答案少于预测答案的代价）。通过对这个自定义损失函数的优化，模型提供的预测值更有可能最大化收益。在TensorFlow中，可以通过以下代码来实现这个损失函数。
\begin{minted}{python}
loss = tf.reduce_sum(tf.select(tf.greater(v1, v2), (v1 - v2) * a, (v2 - v1) * b))
\end{minted}

以下代码展示了tf.select函数和tf.greater函数的用法。
\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{python}
import tensorflow as tf
v1 = tf.constant([1.0, 2.0, 3.0, 4.0])
v2 = tf.constant([4.0, 3.0, 2.0, 1.0])

sess = tf.InteractiveSession()
print tf.greater(v1, v2).eval()
# 输出[False False True True]

print tf.select(tf.greater(v1, v2), v1, v2).eval()
# 输出[4. 3. 3. 4.]
sess.close()
\end{minted}


\subsection{滑动平均模型}
tf.train.ExponentialMovingAverage



\subsection{计算图的概念}
TensorFlow provides multiple APIs.

The lowest level API--TensorFlow Core-- provides you with complete programming control. We recommend TensorFlow Core for machine learning researchers and others who require fine levels of control over their models.

The higher level APIs are built on top of TensorFlow Core. These higher level APIs are typically easier to learn and use than TensorFlow Core. In addition, the higher level APIs make repetitive tasks easier and more consistent between different users. A high-level API like tf.estimator helps you manage data sets, estimators, training and inference.

This guide begins with a tutorial on TensorFlow Core. Later, we demonstrate how to implement the same model in tf.estimator. Knowing TensorFlow Core principles will give you a great mental model of how things are working internally when you use the more compact higher level API.

\subsubsection{Tensors}
The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions. Here are some examples of tensors:

\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{python}
3 # a rank 0 tensor; this is a scalar with shape []
[1., 2., 3.] # a rank 1 tensor; this is a vector with shape [3]
[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]
[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]
\end{minted}


\subsubsection{TensorFlow Core tutorial}

Importing TensorFlow

The canonical import statement for TensorFlow programs is as follows:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
import tensorflow as tf
\end{minted}

This gives Python access to all of TensorFlow's classes, methods, and symbols. Most of the documentation assumes you have already done this.

\subsubsection{The Computational Graph}
You might think of TensorFlow Core programs as consisting of two discrete sections:

\begin{enumerate}
\item Building the computational graph.
\item Running the computational graph.
\end{enumerate}

A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. Each node takes zero or more tensors as inputs and produces a tensor as an output. One type of node is a constant. Like all TensorFlow constants, it takes no inputs, and it outputs a value it stores internally. We can create two floating point Tensors node1 and node2 as follows:

\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{python}
node1 = tf.constant(3.0, dtype=tf.float32)
node2 = tf.constant(4.0) # also tf.float32 implicitly
print(node1, node2)
# 输出如下：
# Tensor("Const:0", shape=(), dtype=float32) Tensor("Const_1:0", shape=(), dtype=float32)
\end{minted}

Notice that printing the nodes does not output the values 3.0 and 4.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime.

The following code creates a Session object and then invokes its run method to run enough of the computational graph to evaluate node1 and node2. By running the computational graph in a session as follows:

\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{python}
node1 = tf.constant(3.0, dtype=tf.float32)
node2 = tf.constant(4.0) # also tf.float32 implicitly
sess = tf.Session()
print(sess.run([node1, node2]))
# 输入如下：
# [3.0, 4.0]
\end{minted}

We can build more complicated computations by combining Tensor nodes with operations (Operations are also nodes). For example, we can add our two constant nodes and produce a new graph as follows:
\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
node3 = tf.add(node1, node2)
print("node3:", node3)
print("sess.run(node3):", sess.run(node3))

# 输出如下：
# node3: Tensor("Add:0", shape=(), dtype=float32)
# sess.run(node3): 7.0
\end{minted}

TensorFlow provides a utility called TensorBoard that can display a picture of the computational graph. Here is a screenshot showing how TensorBoard visualizes the graph:

TensorBoard screenshot

As it stands, this graph is not especially interesting because it always produces a constant result. A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later.

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b  # + provides a shortcut for tf.add(a, b)
\end{minted}

%The preceding three lines are a bit like a function or a lambda in which we define two input parameters (a and b) and then an operation on them. We can evaluate this graph with multiple inputs by using the feed_dict argument to the run method to feed concrete values to the placeholders:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
print(sess.run(adder_node, {a: 3, b: 4.5}))
print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))

# 输出：
# 7.5
# [ 3.  7.]
\end{minted}

In TensorBoard, the graph looks like this:

TensorBoard screenshot

We can make the computational graph more complex by adding another operation. For example,

%add_and_triple = adder_node * 3.
%print(sess.run(add_and_triple, {a: 3, b: 4.5}))
produces the output

22.5
The preceding computational graph would look as follows in TensorBoard:

TensorBoard screenshot

In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
x = tf.placeholder(tf.float32)
linear_model = W * x + b
\end{minted}
Constants are initialized when you call tf.constant, and their value can never change. By contrast, variables are not initialized when you call tf.Variable. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:

%init = tf.global_variables_initializer()
sess.run(init)
It is important to realize init is a handle to the TensorFlow sub-graph that initializes all the global variables. Until we call sess.run, the variables are uninitialized.

%Since x is a placeholder, we can evaluate linear_model for several values of x simultaneously as follows:

%print(sess.run(linear_model, {x: [1, 2, 3, 4]}))
to produce the output

%[ 0.          0.30000001  0.60000002  0.90000004]
We've created a model, but we don't know how good it is yet. To evaluate the model on training data, we need a y placeholder to provide the desired values, and we need to write a loss function.

%A loss function measures how far apart the current model is from the provided data. We'll use a standard loss model for linear regression, which sums the squares of the deltas between the current model and the provided data. linear_model - y creates a vector where each element is the corresponding example's error delta. We call tf.square to square that error. Then, we sum all the squared errors to create a single scalar that abstracts the error of all examples using tf.reduce_sum:

y = tf.placeholder(tf.float32)
%squared_deltas = tf.square(linear_model - y)
%loss = tf.reduce_sum(squared_deltas)
%print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
producing the loss value

23.66
We could improve this manually by reassigning the values of W and b to the perfect values of -1 and 1. A variable is initialized to the value provided to tf.Variable but can be changed using operations like tf.assign. For example, W=-1 and b=1 are the optimal parameters for our model. We can change W and b accordingly:

%fixW = tf.assign(W, [-1.])
%fixb = tf.assign(b, [1.])
%sess.run([fixW, fixb])
%print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
The final print shows the loss now is zero.

0.0
We guessed the "perfect" values of W and b, but the whole point of machine learning is to find the correct model parameters automatically. We will show how to accomplish this in the next section.

tf.train API

A complete discussion of machine learning is out of the scope of this tutorial. However, TensorFlow provides optimizers that slowly change each variable in order to minimize the loss function. The simplest optimizer is gradient descent. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. In general, computing symbolic derivatives manually is tedious and error-prone. Consequently, TensorFlow can automatically produce derivatives given only a description of the model using the function tf.gradients. For simplicity, optimizers typically do this for you. For example,

optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
%sess.run(init) # reset values to incorrect defaults.
for i in range(1000):
%  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})

%print(sess.run([W, b]))
results in the final model parameters:

%[array([-0.9999969], dtype=float32), array([ 0.99999082],
 dtype=float32)]
Now we have done actual machine learning! Although doing this simple linear regression doesn't require much TensorFlow core code, more complicated models and methods to feed data into your model necessitate more code. Thus TensorFlow provides higher level abstractions for common patterns, structures, and functionality. We will learn how to use some of these abstractions in the next section.

Complete program

The completed trainable linear regression model is shown here:

\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
import tensorflow as tf
# 模型参数
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
# 模型输入和输出
x = tf.placeholder(tf.float32)
linear_model = W * x + b
y = tf.placeholder(tf.float32)

loss = tf.reduce_sum(tf.square(linear_model - y))
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)

# training data
x_train = [1, 2, 3, 4]
y_train = [0, -1, -2, -3]

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
    sess.run(train, {x: x_train, y: y_train})

# 评估训练的正确率
curr_W, curr_b, curr_loss = sess.run([W, b, loss],
                                    {x: x_train, y: y_train})
print("W: %s b: %s loss: %s" % (curr_W, curr_b, curr_loss))

# 输出如下：
# W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11
\end{minted}

Notice that the loss is a very small number (very close to zero). If you run this program, your loss may not be the exact same because the model is initialized with pseudorandom values.

This more complicated program can still be visualized in TensorBoard TensorBoard final model visualization

tf.estimator

tf.estimator is a high-level TensorFlow library that simplifies the mechanics of machine learning, including the following:

running training loops
running evaluation loops
managing data sets
tf.estimator defines many common models.

Basic usage

Notice how much simpler the linear regression program becomes with tf.estimator:

\newpage
\begin{minted}[mathescape, linenos, numbersep=5pt, frame=lines, framesep=2mm]{python}
import tensorflow as tf
import numpy as np
feature_columns = [tf.feature_column.numeric_column("x", shape=[1])]
estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {"x": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {"x": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {"x": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)
estimator.train(input_fn=input_fn, steps=1000)
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print("train metrics: %r" % train_metrics)
print("eval metrics: %r" % eval_metrics)
# 输出如下：
# train metrics: {'loss': 1.2712867e-09, 'global_step': 1000}
# eval metrics: {'loss': 0.0025279333, 'global_step': 1000}
\end{minted}

Notice how our eval data has a higher loss, but it is still close to zero. That means we are learning properly.

A custom model

tf.estimator does not lock you into its predefined models. Suppose we wanted to create a custom model that is not built into TensorFlow. We can still retain the high level abstraction of data set, feeding, training, etc. of tf.estimator. For illustration, we will show how to implement our own equivalent model to LinearRegressor using our knowledge of the lower level TensorFlow API.

%To define a custom model that works with tf.estimator, we need to use tf.estimator.Estimator. tf.estimator.LinearRegressor is actually a sub-class of tf.estimator.Estimator. Instead of sub-classing Estimator, we simply provide Estimator a function model_fn that tells tf.estimator how it can evaluate predictions, training steps, and loss. The code is as follows:

import numpy as np
import tensorflow as tf

%# Declare list of features, we only have one real-valued feature
%def model_fn(features, labels, mode):
%  # Build a linear model and predict values
%  W = tf.get_variable("W", [1], dtype=tf.float64)
%  b = tf.get_variable("b", [1], dtype=tf.float64)
%  y = W * features['x'] + b
%  # Loss sub-graph
%  loss = tf.reduce_sum(tf.square(y - labels))
%  # Training sub-graph
%  global_step = tf.train.get_global_step()
  optimizer = tf.train.GradientDescentOptimizer(0.01)
%  train = tf.group(optimizer.minimize(loss),
%                   tf.assign_add(global_step, 1))
%  # EstimatorSpec connects subgraphs we built to the
%  # appropriate functionality.
  return tf.estimator.EstimatorSpec(
      mode=mode,
      predictions=y,
      loss=loss,
%      train_op=train)

%estimator = tf.estimator.Estimator(model_fn=model_fn)
%# define our data sets
%x_train = np.array([1., 2., 3., 4.])
%y_train = np.array([0., -1., -2., -3.])
%x_eval = np.array([2., 5., 8., 1.])
%y_eval = np.array([-1.01, -4.1, -7, 0.])
%input_fn = tf.estimator.inputs.numpy_input_fn(
%    {"x": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
%train_input_fn = tf.estimator.inputs.numpy_input_fn(
%    {"x": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
%eval_input_fn = tf.estimator.inputs.numpy_input_fn(
%    {"x": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

%# train
%estimator.train(input_fn=input_fn, steps=1000)
%# Here we evaluate how well our model did.
%train_metrics = estimator.evaluate(input_fn=train_input_fn)
%eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
%print("train metrics: %r"% train_metrics)
%print("eval metrics: %r"% eval_metrics)
When run, it produces

%train metrics: {'loss': 1.227995e-11, 'global_step': 1000}
%eval metrics: {'loss': 0.01010036, 'global_step': 1000}
%Notice how the contents of the custom model_fn() function are very similar to our manual model training loop from the lower level API.

Next steps

Now you have a working knowledge of the basics of TensorFlow. We have several more tutorials that you can look at to learn more. If you are a beginner in machine learning see MNIST for beginners, otherwise see Deep MNIST for experts.


\href{https://arxiv.org/abs/1603.04467}{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}

\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{python}
import sys
import tensorflow as tf
a = tf.constant(2, name='a')
b = tf.constant(3, name='b')
x = tf.add(a, b, name='add')

with tf.Session() as sess:
    print(sess.run(x))




import sys
import tensorflow as tf

a = tf.constant(2, name='a')
b = tf.constant(3, name='b')
x = tf.add(a, b, name='add')

writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())
with tf.Session() as sess:
    #writer = tf.summary.FileWriter('./graphs', sess.graph)
    print(sess.run(x))

writer.close()


tf.nn.embedding_lookup(params, ids, partition_strategy='mod', name=None,
                       validate_indices=True, max_norm=None)



tf.train.Saver.save(sess, save_path, global_step=None...)
tf.train.Saver.restore(sess, save_path)
\end{minted}

\begin{minted}[mathescape,
              linenos,
              numbersep=5pt,
              frame=lines,
              framesep=2mm]{shell}
$ python -m tensorboard.main --logdir="./graphs" --port 6006
\end{minted}

\ifx\engineeringnotes\undefined
    \input{\notesroot/tail}
\fi
