\ifx\projectsnotes\undefined
    \providecommand{\notesroot}{../..}
    \providecommand{\sentencepairroot}{.}

    \title{句对匹配}
    \author{Donald Cheung\\jianzhang9102@gmail.com}
    \date{\today\footnote{文档编写开始于2018年5月17日}}

    \input{\notesroot/head}
\else
    \providecommand{\sentencepairroot}{\projectsroot/sentence_pair_classification}
\fi

\chapter{句对匹配}

\section{数据集介绍}

\subsection{Quora Question Pairs}
官方比赛链接：\href{https://www.kaggle.com/c/quora-question-pairs}{Quora Question Pairs}

数据集链接：\url{https://pan.baidu.com/s/1mij3Nza}

\subsubsection{问题详情}
\subsubsection{背景}
Quora是美国版的知乎，月活用户超过1亿，很多人会问很类似的问题。重复问题的出现，会使得信息需求者花费更多的时间去寻找答案，而答主需要对一样的问题解答很多遍。

此数据需要解决的问题就是，判断一对问题是否是重复性问题，也就是说判断两个问题是否是同一个意思。

需要注意的是，数据集中的lable是由人为标注的，也就是说并不是100\%正确的。

\subsubsection{评估}
用log loss作为评估标准。

\section{实验}

\begin{enumerate}
\item 基于词频的cosine相似度计算：[2017-03-21 21:20]
成绩：0.75402

做法：直接使用sklearn的CountVectorizer，然后获取每个问题的切词列表，统计出频次，计算两个向量的相似度。

TODO: 
\begin{itemize}
\item 基于tf-idf特征的方法
\item 两个问题的BOW向量，直接通过LR训练
\item 获取word的Embedding向量，然后加和取平均，获得问题的向量，然后（1）计算两个向量的相似度；（2）直接拼接两个向量，接入LR训练模型
\item 使用论文`Distributed Representations of Sentences and Documents`中的想法
\item 使用fastText工具
\item 使用LSTM
\item 方法参考：https://www.kaggle.com/c/quora-question-pairs/discussion/30340
\end{itemize}

\end{enumerate}


\section{相关参考文献}

\cite{Parikh:2016aa} 提出


\ifx\projectsnotes\undefined
    \input{\notesroot/tail}
\fi
